\chapter{Dynamic Agent Safety Logic}
	\label{CH_03}

%\section{Interpreting $\Kns{}$ and $\Bels{}$}
%Before continuing, we must clearly articulate the intended interpretation of our knowledge and belief operators. Epistemic logic can produce some counterintuitive results if the knowledge operator is interpreted inappropriately for the system. For example, the standard Distribution Axiom of knowledge, $\Kns{i}(\varphi \iimplies \psi) \iimplies (\Kns{i}\varphi \iimplies \Kns{i}\psi)$ states that knowledge is closed under implication. This presents several problems when the operator is interpreted as ``agent $i$ actively knows right now that $\varphi$". For empirical knowledge, the threat of global skepticism looms, because presumably $i$ knows that she exists as an embodied agent in the external world only if she is not a mind in a simulated reality. Therefore, she knows she is an embodied agent in the external world only if she knows she is not a mind in a simulated reality. By hypothesis, the skeptic would say, she does not know she is not a mind in a simulated reality. Therefore, she does not know she is an embodied agent in the external world. For statements of pure logic, the Distribution Axiom states that agents know all logical truths. 

%The standard interpretation in the literature for an epistemic logic with just a knowledge operator is that ``agent $i$ \emph{implicitly} knows that $\varphi$," meaning something like the claim that $\varphi$ is a live candidate for knowledge for $i$, should $i$ ever examine the proposition. For doxastic logic, the same concern arises for belief, as it has the Distribution Axiom as well. The interpretation here is usually something like ``agent $i$'s beliefs \emph{commit} $i$ to $\varphi$," or ``$i$ is disposed to believe that $\varphi$. In both cases, the interpretation moves away from an active, explicit occurrence of the proposition in the agent's mind in order to avoid the weirdness of closure. We do not adopt this interpretation. We construct a logic that combines knowledge and belief in such a way that active explicit knowledge and belief are interpretations that make sense, for empirical knowledge and belief. We leave the problem of logical omniscient unresolved.

%Our interpretation is analogous to a debate that occurs concerning the interpretation of probabilities among frequentists and Bayesians. Frequentists hold that probabilities represent objective frequencies that occur in the world, which can be counted through controlled experiment, and which should directly map to the probability for an event. For Bayesians, probabilities represent subjective uncertainty in the mind of a reasoner. Rather than constructing a model based on one or the other of these notions, we construct a model that includes both the notion of objectively available evidence and subjectively available evidence.

%\begin{definition}[Objectively Available Evidence]~\label{obj_ev}
%	Evidence is \emph{objectively available} for proposition $\varphi$ if and only if some source of information exists in the actual world that supports the proposition $\varphi$.
%\end{definition}

%What is it for a source of information to exist that supports a proposition? An event occurs which satisfies the proposition, and observable consequences of the event share mutual information with the proposition, and potentially other propositions. Thus, when a coin lands with \emph{heads} facing up, the light reflecting off the coin's surface is a source of information that supports the propositions that ``the coin landed \emph{heads} up," and ``the coin is unfair and has two \emph{heads}," and ``the coin landed \emph{tails} down." The light reflecting off the surface is objectively available evidence. If anyone sees the light reflecting off the coin, then this evidence becomes subjectively available to them. 

%\begin{definition}[Subjectively Available Evidence]~\label{subj_ev}
%	Evidence is \emph{subjectively available} to agent $i$ for proposition $\varphi$ if and only if $i$ has immediate mental awareness of some information, accurate or inaccurate, that supports the proposition $\varphi$.
%\end{definition}

%Seeing a coin land \emph{heads} is subjectively available evidence to the agent that sees it. Later, misremembering the event, and believing that one saw the coin land \emph{tails} is also subjectively available evidence. But the objectively available evidence is still that light that reflected off the coin's surface, which was in a \emph{heads} up orientation at the time. If someone, say Alice, tells you they saw a ghost, this is objectively available evidence for the propositions, ``Alice saw a ghost," and ``Alice claims to have seen a ghost." Whether you believe both of these propositions or not depends on myriad things, which this model does not address, but the soundwaves emanating from Alice's mouth when she tells you that she saw a ghost are objectively available evidence. If she said it out loud to no one in particular in a room she thought was empty of people, but a tape recorder was running, then her saying it and causing the information to be stored on the tape recorder would constitute objectively available evidence. When someone listens to the tape recorder, it becomes subjectively available evidence, and the possible worlds under her consideration include potentially both propositions, and almost certainly the latter.

%Thus, from the actual world, epistemically possible worlds are created by objectively available evidence, and doxastically possible worlds are created by subjectively available evidence. At those doxastically possible worlds, further epistemically possible worlds may exist, but they are no longer generated by objectively available evidence. Instead, they are generated by subjective evidence of objective evidence. Consider the coin flip. When the coin lands \emph{heads} up, all epistemically possible worlds become constrained to those in which the proposition ``the coin landed \emph{heads} up" is true. When $i$ sees it happen, doxastically possible worlds exist in which the propositions ``the coin landed \emph{heads} up" and ``The evidence tells me that the coin landed \emph{heads} up" and ``I know that the coin landed \emph{heads} up" are true, because she is perceiving the objectively available evidence. Her perception of it makes it subjective, but the perception is that it is objective, which is true of the information flowing from the event, but not of the information flowing from her perception of it.
%Thus, epistemically possible worlds are tied to the actual world in some sense, and doxastically possible worlds depend on an agent's mental consideration. What about the epistemic relation beneath the doxastic layer? For example, what about when $i$ remembers the event of the cThat is, what about the situation in which $i$ has subjectively available evidence for worlds in which her evidence is also objectively available? We maintain that there is a difference, but it is a subjective difference. When $i$ considers worlds possible in which she has objective evidence for a proposition, that evidence is subjectively objective, because her subjectively available evidence indicates to her that she has objective evidence. Ultimately, though, subjectively objective evidence is subjective. We capture this notion with the frame relation that $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$. Once it enters the subjective realm, it can never leave and be truly objective again; but it seems to $i$ that it is objective. So, when someone misremembers an event they observed, in remembering it they take a step down the doxastic possibility relation, and in activating it as evidence, they feel as if they are activating objective evidence, and so they take a step down an epistemic relation. But it is not objective evidence, it is mediated by the internal, subjective filter of the agent's own mind.

%We leave the notions of ``source of information existing", ``support for propositions", and ``immediate mental awareness" unanalyzed, but trust that they are intuitively reducible to familiar concepts for the reader. They articulate the difference between experimental support published in a peer-reviewed journal article that supports a proposition, and an agent reading and believing the evidence in the article. In the former case, her epistemically possible worlds will include some in which the proposition is true, while in the latter case, her doxastically possible worlds will all come to satisfy the proposition. If she reads the article and uses it to update her beliefs according to some probabilistic account, perhaps the some doxastically worlds satisfy the proposition, while others do not, but she now considers the proposition possibly true. It was epistemically possible for her so long as there never has been objectively available evidence ruling it out, but it became doxastically possible for her once the evidence became subjectively available to her.

%This still leaves the problem of logical omniscience to be addressed. It gets generated for our logic specifically in the following way. All propositional tautologies are theorems of the logic. By the rule of $\Kns{i}$ Necessitation, all theorems are known. The Distribution Axiom of $\Kns{i}$ over implication says if a theorem is known, and $i$ knows that the theorem $\varphi$ implies $\psi$, then $i$ knows $\psi$. Since knowledge implies belief, $\Bels{i}\psi$. Thus, $i$ knows and believes every mathematical theorem. Our solution depends on a function that partitions the set of atomic propositions into an \emph{active} set and an \emph{inactive} set.

%\begin{definition}[Active Set]~\label{active_set}
%	\emph{For a model $M$ with set of atomic propositions} $AtProp$\emph{, the active set} active  $\stackrel{def}{=} \{p\  |\  p \in AtProp \aand \mathit{activate(p)} = \mathit{True}\}$.
%\end{definition}

%\begin{definition}[Inactive Set]~\label{inactive_set}
%	\emph{For a model $M$ with set of atomic propositions} $AtProp$\emph{, the inactive set} inactive  $\stackrel{def}{=} \{p\  |\  p \in AtProp \aand p\not\in \mathit{active}\}$.
%\end{definition}

%These sets formalize the notion that a human-like agent can actively consider only a limited number of atomic propositions at a time. When an atomic proposition is \emph{inactive}, it will be excluded from the model. Just as we build simple Kripke structures with only a few atomic propositions included, so do humans actually reason this way, with only a few atomic propositions under active consideration at a time. 

%Now we can ameliorate the problem of skepticism by appealing to our notion of evidence as the source of possible worlds, and the fact that models include only active atomic propositions. For logic and mathematics, evidence consists in proofs. A proof is a set of sentences realizing the sequence of deductions from axioms and theorems to the proved theorem. A proof is tokenized when it is instantiated in the form of writing or speech. We say a tokenized proof constitutes objectively available evidence for a theorem, and perceiving that tokenized proof constitutes subjectively available evidence. Thus, even though there may be a Platonic proof that P!=NP out there waiting to be instantiated, until it is instantiated, no such objective evidence is available to human-like reasoners. That's why humans truly and without contradiction say that they do not know whether P=NP.

%Furthermore, we can deny the problematic part of the problem of logical omniscience by denying that agents know all tautological logical implications. They know the ones with tokenized proofs. The ones without tokenized proofs are actually unknown to us. In order to identify an inconsistency, a critic would have to instantiate a proof of a previously unknown theorem, and in so doing, the logic under consideration here would update to include it as objectively available evidence for formulas consisting of atomic propositions that are active. 

The logic for reasoning about information flow in knowledge games is called Dynamic Epistemic Logic (DEL). As its name suggests, it combines elements of epistemic logic and dynamic logic. Epistemic logic is the static logic for reasoning about knowledge, and dynamic logic is used to reason about actions. In dynamic logic semantics, nodes are states of the system (or of the world), and relations on nodes are transitions via programs or actions from node to node. If we think of each node in dynamic logic as being a model of epistemic logic, then actions become relations on models, representing transitions from one multi-agent epistemic model to another. For example, if we have a static epistemic model $M1$ representing the knowledge states of agents $1$ and $2$ at a moment, then the action $``p?"$ is a relation between $M1$ and $M2$, a new static epistemic model of $1$'s and $2$'s knowledge after the question is asked. All of this is captured by DEL.

\begin {center}
\begin {tikzpicture}[-latex ,auto ,node distance =3 cm and 4cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white , bottom color = white ,
	draw, text=black , minimum width =1 cm}]

\node[state] (A)  {$M1$};
\node[state] (B) [right =of A] {$M2$};

\path (A) edge  node[above] {$``p?"$} (B);
%\path (C) edge [bend left =25] node[below =0.15 cm] {$1/2$} (A);
%\path (A) edge [bend right = -15] node[below =0.15 cm] {$1/2$} (C);
%\path (A) edge [bend left =25] node[above] {$1/4$} (B);
%\path (B) edge [bend left =15] node[below =0.15 cm] {$1/2$} (A);
%\path (C) edge [bend left =15] node[below =0.15 cm] {$1/2$} (B);
%\path (B) edge [bend right = -25] node[below =0.15 cm] {$1/2$} (C);
\end{tikzpicture}
\end{center}

The above figure illustrates the relationship between static epistemic models and dynamic logic models. As a purely dynamic model, the figure shows the action $``p?"$ transitioning between nodes $M1$ and $M2$. If we were to zoom in on the nodes, we would see their structure as epistemic models, with their own nodes and edges, representing possible worlds and epistemic relations.

We are concerned with an additional element: the \emph{safety} status of an action, and an agent's knowledge and belief about that. To capture this, we extend DEL and call the new logic Dynamic Agent Safety Logic (\DASL). The remainder of this section presents \DASL's syntax, semantics, and proves its soundness. 
\section{Syntax and Semantics}
\subsection{Syntax}
\DASL\  has the following syntax.
%, combining elements of Dynamic Epistemic Logic (DEL) and Agent Safety Logic (ASL).

	$$ \varphi \ ::=\   \lpp  \bnf \tlnot \varphi \bnf \varphi \tland \varphi  \bnf \Kns{i} \varphi \bnf \Bels{i}\varphi \bnf \Pal{A,\laa}\varphi \bnf\SPal{A,\laa}\varphi,$$

where $\lpp \in AtProp$ is an atomic proposition letter drawn from a finite set of such letters , $\mathbf{i}$ refers to $i \in Agents$, $\mathbf{\laa}$ is the name of an action, called an action token, belong to a set of such tokens, $Actions$, and $\mathbf{A}$ refers to an action model. The knowledge operator $\Kns{i}$ indicates that ``agent \emph{i} knows that ..." Similarly, the operator for belief, $\Bels{i}$ can be read, ``agent \emph{i} believes that..." The notion of action tokens and structures will be defined in the semantics. The operators $\Pal{A,\laa}$ and $\SPal{A,\laa}$ are the dynamic operators for action $\laa$ from action structure $A$ occurring in the former case, and happening safely in the latter case. One can read the action operators as ``after $\laa$ from $A$ occurs (\emph{safely}), $\varphi$ holds in all resulting worlds.' We define the dual modal operators $\Poss{i}$, $\BPoss{i}$, $\PalPos{A,\laa}$, and $\SPalPos{A,\laa}$ in the usual way. 

The semantics of \DASL\ involve two structures that are defined simultaneously, one for epistemic models, and one for action structures capturing the transition relation among epistemic models. Additionally, we define numerous helper functions that straddle the division between metalanguage and object language. 

\subsection{Metalanguage}

The metalanguage defining \DASL\ consists of traditional Kripke models, and action models, with functions for action pre- and post-conditions and the product update of Kripke and action models~\cite{DEL}.

\subsubsection{Kripke (Relational) Structure}%$\mathbf{Definition}$. Kripke Model.\\ 
A Kripke structure, called model $M$, is a tuple $\langle W, \Rel{k}^i, \Rel{b}^i, w, V \rangle$. It is a set of worlds $W$, epistemic and doxastic relations on worlds for agents, a world denoting the actual world, and a valuation function \emph{V} mapping atomic propositions to the set of worlds satisfying them.

\subsubsection{Action Model}
%$\mathbf{Definition}$. Action Structure.\\ 
An action structure $\mathbf{A}$ is a tuple $\langle Actions,\chi_{k}^i, \chi_{b}^i, pre, post \rangle$. It is a set of action tokens, sets of epistemic and doxastic relations on action tokens for agents, action pre- and post-condition functions, and safe action pre-condition functions.  

An action model captures the agents' subjective perspectives of an event's occurrence. For example, consider a situation in which Alice flips a coin and Bob calls whether it is \emph{heads} or \emph{tails}. The action model imposes no precondition for occurring, represented by the value $\top$, and each action token's post-condition maps $\top$ to \emph{heads} or \emph{tails} respectively. Before Alice peeks to see what it is, the Action Model $\mathbf{A}$ looks like (omitting the safety pre-conditions and doxastic relations, for simplicity):
\begin{figure}[H]
\begin{center}
\begin {tikzpicture}[auto ,node distance =7 cm and 7cm ,on grid ,
semithick ,
state/.style ={ rectangle ,top color =white , bottom color = white ,
	draw, text=black }]
\node[state] (A) {\begin{tabular}{l} $\underline{\laa}$ \\ $pre$: $\top$ \\ $post$: \{$\tlnot \emph{heads} \mapsto$ \emph{heads}\}
	\end{tabular}};
	\node[state] (B) [right =of A] {\begin{tabular}{l} $\underline{\beta}$ \\ $pre$: $\top$ \\ $post$: \{$\tlnot \emph{tails} \mapsto$ \emph{tails}\}
		\end{tabular}};
\path[]
(A) edge node {\emph{Alice, Bob}} (B);
\end{tikzpicture}
\end{center}
\caption{Action Model for ``Alice flips a coin"}
\label{fig: flip}
\end{figure}
We use rectangles for action tokens to distinguish them from possible worlds in Kripke Structures. Each action token is marked by a token name, $\laa$, $\beta$, etc. The labels \emph{Alice, Bob} indicate the agents' epistemic (------) relations. When the relations lack direction, it indicates bi-directionality, and every action token has a looping epistemic relation to itself that we omit in order to keep the pictures simpler. In Figure~\ref{fig: flip}, neither Alice nor Bob sees whether the coin lands \emph{heads} or \emph{tails}, but the post-condition of the action is that the proposition expressing the state of the coin becomes \emph{heads} or \emph{tails}. Note that Action Models themselves do not have propositions true and false at them, but rather have pre-conditions and post-conditions for execution of their tokens, and modal relations over the token pairs. The action model for ``Alice peeks" is:

\begin{figure}[H]
\begin{center}
\begin {tikzpicture}[auto ,node distance =7 cm and 7cm ,on grid ,
	semithick , 
	state/.style ={ rectangle ,top color =white , bottom color = white ,
		draw, text=black}]
	\node[state] (A) {\begin{tabular}{l} $\underline{\laa}$ \\ $pre$: \emph{heads} \\ $post$: $\emptyset$
	\end{tabular}};
	\node[state] (B) [right =of A] {\begin{tabular}{l} $\underline{\beta}$ \\ $pre$: \emph{tails} \\ $post$: $\emptyset$
	\end{tabular}};
	\path[]
	(A) edge node {\emph{Bob}} (B);
\end{tikzpicture}
\end{center}
\caption{Action Model for ``Alice peeks"}
\label{fig: peek}
\end{figure}

In Figure~\ref{fig: peek}, the epistemic and doxastic relations for Alice have vanished. In the event that Alice peeks and sees \emph{heads}, she sees that the coin landed \emph{heads}, and similarly for \emph{tails}. Bob, however, still considers it possible that Alice peeked and saw \emph{heads} or that she peeked and saw \emph{tails}. However, Bob knows that Alice knows the coin's state. To represent Alice surreptitiously peeking, we use the following action model:
 
\begin{figure}[H]
	\begin{center}
		\begin {tikzpicture}[auto ,node distance =5 cm and 5cm ,on grid ,
		semithick ,
		state/.style ={ rectangle ,top color =white , bottom color = white ,
			draw, text=black }]
		\node[state] (A) 
			{\begin{tabular}{l} 
				$\underline{\laa}$ \\ $pre$: \emph{heads} \\ $post$: $\emptyset$
			\end{tabular}};
		\node[state] (B) [right =of A] 
			{\begin{tabular}{l} 
				$\underline{\beta}$ \\ $pre$: \emph{tails} \\ $post$: $\emptyset$
			\end{tabular}};
		\node[state] (C) [below right =of A]
			{\begin{tabular}{l}
				$\underline{\gamma}$ \\ $pre$: \emph{tails} \\ $post$: $\emptyset$
			\end{tabular}};
		\node[state] (D) [below =of A]
		{\begin{tabular}{l}
				$\underline{\delta}$ \\ $pre$: \emph{heads} \\ $post$: $\emptyset$
			\end{tabular}};
		\path[]
			(A) edge [bend left, above] node {\emph{Alice, Bob}} (B)
			(C) edge [-latex] node {\emph{Bob}} (B)
			(D) edge [-latex] node {\emph{Bob}} (A);
		\end{tikzpicture}
	\end{center}
	\caption{Action Model for ``Alice secretly peeks"}
	\label{fig: secret_peek}
\end{figure} 

In Figure~\ref{fig: secret_peek}, Alice knows the state of the coin, Bob has the false impression that Alice is, like him, totally ignorant about the coin's state, and Alice knows this about him. But again, the propositions are not true or false in the Action Model itself; it just describes the pre- and post-conditions and the subjective perspectives of the action. Once the Action Model is used during the application of the \emph{Update Function} (described below), in conjunction with a Kripke Structure, it produces worlds with true and false propositions.


\subsubsection{Model Relation}
%$\mathbf{Definition}$. Model Relation.\\ 
Just as $\Rel{k}^i$ denotes a relation on worlds, $\llbracket (A,\laa)_i \rrbracket$ denotes a relation on Kripke model-world pairs. It represents the relation that holds between $M,w$ and $M',w'$ when agent $i$ engages in action $(A,\laa)$ at $M,w$ and causes the world to transition to $M',w'$.


\subsubsection{Precondition Function}
%$\mathbf{Definition}$. 
The Precondition function, $pre :: Actions \mapsto \varphi$, maps an action to the formula capturing the conditions under which the action can occur. For example, if we assume agents tell the truth, then an announcement action has as a precondition that the announced proposition is true, as with regular Public Announcement Logic \cite{PAL}. Compare this function with the weakest precondition from Hoare logic \cite{Hoare}. It returns a formula that must be true prior to an action's execution, just as the weakest precondition of Hoare logic is a formula that must be true prior to a program's execution. 


%$\mathbf{Definition}$. Postcondition Function.\\ $post :: A \times Agents \mapsto \varphi$. The postcondition function assigns a conjunction of atomic propositions to actions performed by an agent, representing the atomic facts of the world that are true after the action occurs:\\ $post(\laa) = \bigwedge_{p\in AtProp}\{p| \forall w,\ update(M,A,w,\laa,i)\models p\}$.

\subsubsection{Postcondition Function}
%$\mathbf{Definition}$. 
The Postcondition function, $post :: Actions \times AtProp \mapsto AtProp$, takes an action token and an atomic proposition, and maps to the corresponding atomic proposition after the action occurs.
\begin{align*}
post(\laa,p)= p\ \mbox{if}\ update(M,A,w,\laa,i)\models p,\  \mbox{else}\ \tlnot p.
\end{align*} 

A similarity is again seen in the strongest postcondition of Hoare logic.

\subsubsection{Update Function}
%$\mathbf{Definition}$.
The Update function, $update :: (Model \times ActionStruct \times W \times Actions \times Agents) \mapsto (Model \times W)$, takes a Kripke model $M$, an action structure $A$, a world from the Kripke model, an action token from the action structure, and an agent $i$ from $Agents$, and returns a new Kripke model-world pair. It represents the effect actions have on models, and is more complicated than other DEL semantics in that actions can change the facts on the ground in addition to the knowledge and belief relations. It is a partial function that is defined iff a model-world pair satisfies the action's preconditions.
\\

$update(M,A,w,\laa,i) = (M',w')\ where:\\$
$1.\  M = \langle W, \{\Rel{k}^{i}\}, \{\Rel{b}^{i}\}, w, V \rangle$\\
$2.\  A = \langle Actions, \{\chi_{k}^i\}, \{\chi_{b}^i\}, \laa, pre, post \rangle$\\
$3.\  M' = \langle W', \{\Rel{k}'^{i}\}, \{\Rel{b}'^{i}\}, w', V' \rangle$\\
$4.\  W' = \{(w,\laa) | w\in W,\laa \in Actions,\ \aand\ w\models pre(\laa)\}$\\
$5.\  \Rel{k}'^{i} = \{((w,\laa),(v,\lbb))|w\Rel{k}^i v \aand \laa \chi_{k}^i \lbb \}$\\
$6.\  \Rel{b}'^{i} = \{((w,\laa),(v,\lbb))|w\Rel{b}^i v \aand \laa \chi_{b}^i \lbb \}$\\
$7.\  w' = (w,\laa)$\\ 
$8.\  V'(p) = post(\laa,p)$

\subsubsection{Safety Precondition Function}
%$\mathbf{Definition}$. 
The Safety Precondition Function, $pre_s :: Actions \mapsto \varphi$, is a more restrictive function than $pre$. Where $pre$ returns the conditions that dictate whether the action is possible, $pre_s$ returns the conditions that dictate whether the action is safely permissible. This function is the key reason the dynamic approach allows for easy inference from action to safety-critical information. It represents an innovation in dynamic logic that this thesis introduces, because it introduces modality to the transition relation among models. Just as in static modal logics two worlds can be related by an epistemic relation but not by a doxastic relation, one static model can dynamically transition to another via a \emph{mere} action even if it cannot do so \emph{safely}. One could extend the analogy to Hoare logic and introduce a weakest secure precondition in addition to a weakest precondition. The weakest secure precondition is stronger than the weakest precondition, because it imposes more restrictions on the state of the system prior to a program's execution.

%$\mathbf{Definition}$. Possibility Valuation Function.\\ $V^p :: Actions \mapsto W.$ The possibility valuation function takes an action and maps it to the set of worlds satisfying that action's precondition:\\ $V^p (\laa) = \{w|w\models pre(\laa)\}$.
%\\
%$\mathbf{Definition}$. Postcondition Valuation Function.\\ $V^{post} :: Actions \mapsto W.$ The postcondition valuation function maps an action to the worlds that satisfy its postconditions after the update:\\ $V^{post} (\laa) = \{w|w \in M' \aand update(M,A,w,\laa,i)=M',w \models post(\laa)\}$.
%$\mathbf{Definition}$. Safety Valuation Function.\\ $V^s :: Actions \mapsto W.$ The safety valuation function takes an action and maps it to the set of worlds satisfying that action's safety precondition:\\ $V^s (\laa) = \{w|w\models pre_s(\laa)\}$.
%\\
\subsection{Semantics}
\DASL\ has the following relational semantics.

\begin{table}[H]
	\begin{center}
	\begin{tabular}{| c |}
		\hline	

	$M,w \models p  \iiff w \in V(p)$ \\
	$M,w \models \tlnot \varphi  \iiff M,w \not\models \varphi$ \\ 
	$M,w \models \varphi \tland \psi \iiff M,w \models \varphi \aand M,w \models \psi$ \\
	$M,w \models \Kns{i}\varphi \iiff \forall v,\ w\Rel{k}^i v\ \timplies\ M,v \models \varphi$ \\
	$M,w \models \Bels{i}\varphi \iiff \forall v,\ w\Rel{b}^i v\ \timplies\ M,v \models \varphi$ \\
	$M,w \models \Pal{A,\laa}\varphi \iiff \forall M',w',\  (M,w) \llbracket (A,\laa)_i \rrbracket (M',w')$ \\ $\timplies\ M',w' \models \varphi$ \\
	$M,w \models \SPal{A,\laa}\varphi \iiff \forall M',w',\  (M,w) \llbracket (A,\laa)_i \rrbracket^S (M',w')$ \\ $\timplies\ M',w' \models \varphi$\\
	\hline 
	\end{tabular}
	\caption{\DASL\ semantics}
	\end{center}
\end{table}
The definitions of the dynamic modalities make use of a relation between two model-world pairs, which we now define.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|}
	\hline
	\\
	$(M,w)\llbracket (A,\laa)_i\rrbracket (M',w') \iiff M,w \models \pre(\laa)$ \\ $\aand update(M,A,w,\laa,i) = (M',w')$ \\
	\\
	$(M,w)\llbracket (A,\laa)_i \rrbracket^S (M',w') \iiff M,w \models pre_s(\laa)$ \\ $\aand update(M,A,w,\laa,i) = (M',w')$\\
	\\
	\hline 
		\end{tabular}
	\caption{\DASL's dynamic model relations.}
	\end{center}
\end{table}




\subsection{Hilbert System}
\DASL\ is axiomatized by the following Hilbert system.\\

%\begin{tcolorbox}All propositional tautologies are axioms.\\$\Kns{i}$ is T (knowledge relation is reflexive)\\
%	$\Bels{i}$ is KD45 (belief relation is serial, transitive, and Euclidean)\\
%	$\Pal{i,(A,\laa)}$
%	EP1: $\Kns{i}\varphi \iimplies \Bels{i}\varphi$ \\
%	EP2: $\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$\\
%	EP3: $\Bels{i}\varphi \iimplies \Kns{i}\Bels{i}\varphi$\\
%	SP: $\Pal{i,(A,\laa)}\varphi \iimplies \Pal{i,(A,\laa),S}\varphi$\\
%	%\SPalPos{i}{\laa}\varphi \iimplies \PalPos{i}{\laa}\varphi$\\
%	PR: $\PalPos{i}{(A,\laa)}\varphi \iimplies \Bels{i}\SPalPos{i}{(A,\laa)}\varphi$,\\
%\end{tcolorbox}
%\noindent plus the inference rules Modus Ponens and Necessitation for $\Kns{i}$ and $\Bels{i}$.

\begin{table}[H]
\begin{center}
\begin{tabular}{| l r |}
	\hline
    $\Kns{i}(\varphi \iimplies \psi) \iimplies (\Kns{i}\varphi \iimplies \Kns{i}\psi)$ & Distribution of $\Kns{i}$ \\
    $\Kns{i}\varphi \iimplies \varphi$ & Truth Axiom \\
    &\\
    $\Bels{i}(\varphi \iimplies \psi) \iimplies (\Bels{i}\varphi \iimplies \Bels{i}\psi)$ & Distribution of $\Bels{i}$\\
    $\Bels{i}\varphi \iimplies \BPoss{i}\varphi$ & Belief Consistency Axiom\\
%    $\Bels{i}\varphi \iimplies \Bels{i}\Bels{i}\varphi$ & Positive Belief Introspection \\
    $\tlnot\Bels{i}\varphi \iimplies \Bels{i}\tlnot\Bels{i}\varphi$ & Negative Belief Introspection\\
    &\\
    $\Kns{i}\varphi \iimplies \Bels{i}\varphi$ & Knowledge implies Belief \\
    $\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$ & Confidence in Belief\\
%    $\Bels{i}\varphi \iimplies \Kns{i}\Bels{i}\varphi$ & Beliefs are Known\\
	&\\
    $\Pal{A,\laa}p \iiff (post(\laa, pre(\laa)) \iimplies p)$ & Atomic Consequence\\
    $\Pal{A,\laa}\tlnot \varphi \iiff (pre(\laa) \iimplies \tlnot \Pal{A,\laa}\varphi)$ & Action Negation\\
    $\Pal{A,\laa}(\varphi \tland \psi) \iiff (\Pal{A,\laa}\varphi \tland \Pal{A,\laa}\psi)$ & Action Conjunction\\
    $\Pal{A,\laa}\Kns{i}\varphi \iiff (pre(\laa)\iimplies \bigwedge_{\laa\chi_{k}^i\beta}\Kns{i}\Pal{A,\beta}\varphi)$ & Action and Knowledge\\
    $\Pal{A,\laa}\Bels{i}\varphi \iiff (pre(\laa)\iimplies \bigwedge_{\laa\chi_{b}^i\beta}\Bels{i}\Pal{A,\beta}\varphi)$ & Action and Belief\\    
    &\\
%    $\Pal{A,\laa}\Pal{A',\laa'}\varphi \iiff [(A,\laa);(A',\laa')]\varphi$ & Action Composition \\
    $\SPal{A,\laa}p \iiff (post(\laa, pre_s(\laa)) \iimplies p)$ & Safe Atomic Consequence\\
    $\SPal{A,\laa}\tlnot \varphi \iiff (pre_s(\laa) \iimplies \tlnot \SPal{A,\laa}\varphi)$ & Safe Action Negation\\
    $\SPal{A,\laa}(\varphi \tland \psi) \iiff (\SPal{A,\laa}\varphi \tland \SPal{A,\laa}\psi)$ & Safe Action Conjunction\\
    $\SPal{A,\laa}\Kns{i}\varphi \iiff (pre_s(\laa)\iimplies \bigwedge_{\laa\chi_{k}^i\beta}\Kns{i}\SPal{A,\beta}\varphi)$ & Safe Action and Knowledge\\
    $\SPal{A,\laa}\Bels{i}\varphi \iiff (pre_s(\laa)\iimplies \bigwedge_{\laa\chi_{b}^i\beta}\Bels{i}\Pal{A,\beta}\varphi)$ & Safe Action and Belief\\ 
%    $\SPal{A,\laa}\SPal{A',\laa'}\varphi \iiff [(A,\laa);(A',\laa')]\varphi$ & Safe Action Composition \\
	&\\
    $\Pal{A,\laa}\varphi \iimplies \SPal{A,\laa}\varphi$ & Inevitability\\
    $\PalPos{A,\laa}\varphi \iimplies \Bels{i}\SPalPos{A,\laa}\varphi$ & Minimum Rationality\\
    &\\
    From $\vdash \varphi$ and $\vdash \varphi \iimplies \psi$, infer $\vdash\psi$ & Modus Ponens\\
    From $\vdash \varphi$, infer $\vdash \Kns{i}\varphi$ & Necessitation of $\Kns{i}$\\
    From $\vdash \varphi$, infer $\vdash \Pal{A,\laa}\varphi$ & Necessitation of $\Pal{A,\laa}$\\
	\hline
\end{tabular}
\caption{Hilbert System of \DASL}
\end{center}
\end{table}

Above are the axioms characterizing the logic, including the reduction axioms translating formulas with dynamic modalities into purely static formulas.

The reduction axioms are recursively defined on $\varphi$, terminating with propositional atoms. When a dynamic operator, either $\Pal{A,\laa}$ or $\SPal{A,\laa}$, applied to a propositional atom $p$, is translated to a static formula, first the $pre$ (or $pre_s$) function is called on the action $\laa$, which if defined, is then passed through the $post$ function to substitute the atoms that change as a result of the action. If this translation process results in an implication that $p$, then the dynamic formula is true; otherwise, false.

We proceed by defending the axiom schema for the static foundation, then continue with the dynamic extensions.

\subsection{Static Base}~\label{static}
Like other dynamic logics for knowledge and belief, \DASL\ consists of a static base of axiom schemas for the knowledge and belief operators. This section explains and defends \DASL's static base, as they represent a novel axiomatization of formal epistemology and a contribution to the literature by this thesis. 

The standard axiom schema for the knowledge operator, whether for a wholly static logic or for the static base of a dynamic system, is that of the \SFive\ operator, described earlier in section~\ref{epistemic_logic}. This axiom schema for the knowledge operator's role in classical economics was first formalized by Aumann in \cite{Aumann}. In this model, the belief operator is not necessary, because agents do not form false beliefs. They either know a proposition, or they know that they do not know it. This is not the case for humans in most epistemic situations.

%Lower tiers attempt to formalize axioms for \emph{boundedly rational} agents. An ideally rational agent has no limit to her ability to reason about higher order iterations of interactive epistemology. For example, common knowledge is formalized among agents $i$ and $j$ in the following way, where $i,j\in G$, the group:
%
%\begin{eqnarray}~\label{common_knowledge}
%	\mathbb{C}_{G}\varphi \equiv (\varphi \iimplies (\Kns{i}\varphi \tland \Kns{j}\varphi \tland \mathbb{C}_{G}(\Kns{i}\varphi \tland \Kns{j}\varphi))).
%\end{eqnarray}
%
%Thus, an ideally rational agent can carry this to any arbitrary $\mathit{n^{th}}$ order of $i$ knows that $j$ knows that $i$ knows \dots Herein, I refer to the $n$ levels of interactive epistemic knowledge as epistemic depth. Clearly, humans cannot actively carry out this depth of interactive reasoning, and this shows experimentally in games whose solutions require more than two or three levels of depth, \emph{e.g.,} the centipede game. Agents with bounded rationality have their epistemic depths formally bounded, to better reflect the limitations of human reasoning.
%
%Bounding agents in this way allows for formal models that capture how a human agent might realistically deviate from optimal Nash equilibria of games. However, bounding rationality in this way does not allow for agents who act based on false beliefs. A lower tier rationality model might impose bounds on the epistemic depth of its agents and also allow for the agents to make decisions based on false beliefs.

The static base of \DASL\ logic attends to the formalization of agents who can make decisions based on false beliefs, but whose beliefs are all justified. It is a weaker model than \SFive, while still making an idealization about its agents.

Recall the static base of \DASL.

\begin{table}[H]
	\begin{center}
		\begin{tabular}{| l r |}
			\hline
			$\Kns{i}(\varphi \iimplies \psi) \iimplies (\Kns{i}\varphi \iimplies \Kns{i}\psi)$ & Distribution of $\Kns{i}$ \\
			$\Kns{i}\varphi \iimplies \varphi$ & Truth Axiom \\
			&\\
			$\Bels{i}(\varphi \iimplies \psi) \iimplies (\Bels{i}\varphi \iimplies \Bels{i}\psi)$ & Distribution of $\Bels{i}$\\
			$\Bels{i}\varphi \iimplies \BPoss{i}\varphi$ & Belief Consistency Axiom\\
%			$\Bels{i}\varphi \iimplies \Bels{i}\Bels{i}\varphi$ & Positive Belief Introspection \\
			$\tlnot\Bels{i}\varphi \iimplies \Bels{i}\tlnot\Bels{i}\varphi$ & Negative Belief Introspection\\
			&\\
			$\Kns{i}\varphi \iimplies \Bels{i}\varphi$ & Knowledge implies Belief \\
			$\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$ & Confidence in Belief\\
			&\\
%			$\Bels{i}\varphi \iimplies \Kns{i}\Bels{i}\varphi$ & Beliefs are Known\\
			From $\vdash \varphi$ and $\vdash \varphi \iimplies \psi$, infer $\vdash\psi$ & Modus Ponens\\
			From $\vdash \varphi$, infer $\vdash \Kns{i}\varphi$ & Necessitation of $\Kns{i}$\\
			\hline
		\end{tabular}
		\caption{Static Base of \DASL}
	\end{center}
\end{table}

As far as we can tell, this axiom scheme is novel, and disagrees with other attempts to model the interaction of knowledge and belief. The primary point of departure is that the knowledge operator is no longer and \SFive\ operator, but merely a T operator. Thus, it is severely weakened as a modal operator, but the corollary to this fact is that knowledge no longer has the imposing necessary conditions of positive and negative introspection. 

%Defense of \SFive\ for knowledge rests on an interpretation of the knowledge operators not as capturing what agents \emph{actively} know at a moment, but rather what their knowledge allows them to potentially infer. Thus, the Distribution axiom is not a license for logical omniscience at a moment, but rather describes what is logically inferrable from what is known by an agent. Similarly for positive and negative introspection. We do not take this path in interpreting the knowledge operator. Instead, depart from the majority of formal epistemologists and interpret the knowledge operator as what is actively known by an agent at a moment.

%We must justify this interpretation. 
While ours is a model that departs from those that appear in formal epistemology, we shall argue that it does a good job of capturing the prominent theories of knowledge espoused by non-formal epistemologists. Our model is also situated well on the rationality tier for modeling realistic human agents whose beliefs are justified, which is a dramatic improvement, from the perspective of realism, over the higher tiers with \SFive\ common knowledge or \SFive\ bounded rationality.

\subsubsection{Desiderata of a Static Base}
In constructing our static base, we must identify the desirable features to be achieved. A model of knowledge and belief for human-like agents can be assessed by how well it satisfies these desirable features. 

First, the model should be well-balanced in the trade off of normativity \emph{vs.} realism so that it can be used to analyze real-world cases as well as idealized formal cases. It scores well on realism to the extent that it represents the reasoning of human-like agents in environments of relative messiness, like the real world. It scores well on normativity to the extent that its departures from realism are improvements over reality to be strived for. Not all idealizations in models are normative in character, as we shall see.

Second, the model should make sense from an epistemological standpoint, \emph{viz.} the philosophical considerations of epistemologists. To construct a system of epistemic logic is to construct a formal theory of epistemology for \emph{some} type of agent, whether it is a perfect deductive reasoner like a computer over a relatively small database ontology or \emph{homo economicus} in well-structured strategic situations, or an imperfect reasoner like a human in the real world. So far, the latter type of agent has been largely neglected by formal efforts, because attention has been on properties of formal systems, see below, rather than primarily on their philosophical foundations.\footnote{One significant exception to this claim is the study of bounded rationality, which imposes limitations on the number of iterations of $i$ knows that $k$ knows that $i$ knows \dots We regard this approach as valuable, but taking a different approach than ours. Typically, bounded rationality approaches still assume that knowledge is \SFive, while we relax this assumption because we regard it is philosophically untenable.}

Third, the model should be a sound and complete logical system to serve as a static foundation for an extension that treats actions. Just because attention must be paid to the philosophical foundations and motivations for a formal system does not mean that the formal system is off the hook for the standard desiderata of a logic. The logic must avert a collapse of belief and knowledge. The logic must abide by the principle of indistinguishability, where an agent cannot distinguish between possible worlds it cannot rule out. 

\paragraph{1. Normative-Realism Trade-Off} 
A model of rationality is situated in a spectrum trading off realism for normative evalutation and prescription. A totally idealized model like that of game theory or rational choice theory is entirely normative. There is no doubt that the agents being modeled are not anything like human beings. The model presumes normativity by showing that acting like an ideally rational agent results in optimal payoffs possible. So, for humans who want to optimize their decisions for payoffs, acting like ideally rational agents is best. However, ideally rational agents have properties that real humans lack, so unless a human can run a simulated agent on a correctly formalized model of a situation, she is unlikely to identify the correct action. After the fact, with a correctly formalized model of the situation, her decision can be analyzed in a post-mortem, but post-mortems never do any good for their subjects.

% First, we seek a model that is low on the tiers of rationality, so that it achieves a level of realism suitable for human agents but also maintains some normative prescriptions as a theory of rationality. The S5 common knowledge tier describes the behavior of ideally rational agents, and in this sense is wholly normative. However, this level of rationality is not achievable by human reasoners, due to their limited cognitive capacity. Thus, the theory of S5 common knowledge can serve to evaluate decisions made by human agents, and can realistically model only a very limited space of human behaviors. One would expect, however, that this theory of rationality would be an appropriate balance of realism and normativity for future systems of artificial intelligence. 

Theories of bounded rationality achieve more realism, but the trade off of realism and normativity is not clearly balanced. By keeping the \SFive\ knowledge operator and limiting the agents' epistemic depth, theories of bounded rationality seek to model actual human behavior in the rarefied world of games of perfect information, where the agents know the payoff structure and the game tree or game matrix. This is fine for modeling humans in behavioral economics experiments, where they are sitting at a table with a formal description of the game in front of them. But for the messier world of cockpits, emergency rooms, power plants, and automobiles, this assumption of \SFive\ knowledge fails. The difference is between \emph{closed } worlds and \emph{open} worlds. A formal game environment is a closed world, meaning the human is aware of all of the relevant propositions and their truth values, \emph{i.e.,} the game structure. The real world's environment is an open one, where the set of relevant propositions is a mystery, and the truth values of the propositions known to be relevant is a matter of uncertainty. Thus, the achievement of realism in idealized games translates to little normative value in the real world.

%The realism of this latter assumption is dubious, and therefore the theory's applicability is limited. Likewise, theories of bounded rationality with S5 knowledge do not offer clear normative prescriptions or evaluative guidelines. Rather, it appears to be an attempt to makes sense of the following finding of behavioral economics: In some situations, human agents depart from the Nash equilibrium, and they both end up with higher payoffs. The centipede game is a good example. The Nash equilibrium states that player $A$ should immediately take the money on the table, whereas experiments show that humans regularly let the pot build up until a few steps before the end, one of the players realizes what will happen, and takes the majority of the pot. From the perspective of maximizing expected payoffs, it is hard to criticize either player, as each achieved higher payoff from this outcome than they would have in the Nash equilibrium. A theory of bounded rationality takes this at face value, and seeks to build a model for it. With such a model, the hope is to offer general normative guidance for agents with bounded rationality. However, to examine the particular outcome of a centipede game, supposing player $B$ is the one with the minority payoff, we can truly say that $B$ will regret not having taken the majority pot one step earlier, and properly that he \emph{should} have, because then he would have had a higher payoff, and so this outcome is not in subgame perfect equilibrium. If the game is analyzed as a sequence of decisions, the final decision the minority-payoff-receiving player makes is the wrong one, normatively. Bounded rationality with S5 knowledge explains this as bad luck determined by the structure of the game and the first (or second) mover advantage, depending on the players' bounds on epistemic depth. But it is nonetheless true that $B$ could have and should have taken the majority pot one step earlier, and this is not a feature of games with outcomes determined by first (or second) mover advantage, like the game of nim with a 3-4-5 setup (or nim with a 1-3-5-7 setup). 

%With repeat iterations of the centipede game, each player becomes wise to what is happening, and after a couple iterations the Nash equilibrium is reached. So if you are playing the centipede game against someone unfamiliar with the game, and you plan on playing multiple rounds, you will do better overall to let the pot build for a bit, and then play the Nash equilibrium once the other player figures out the game. Thus, the task of the experienced player is not to reason through the game tree and use backward induction as soon as her bounded rationality allows her to, but rather to determine the opposing player's rationality bound and make her play accordingly. It is a different sort of game. Essentially, the experience player must determine whether the new player is a 2-depth type or a 3-depth type, and how quickly he can learn the trick of the game. 

%However, what guidance does the theory offer to a human agent playing centipede for the first time? The agent is bounded in how deep she can reason in the game tree, and the opposing player knows the game and so need not reason through it. The game becomes one of 

%For lower tier theories of bounded rationality with imperfect information, we find agents... 

Other attempts to relax the assumptions of classical game theory abandon the assumption of \SFive\ knowledge and turn toward probability theory in order to capture uncertainty. Uncertainty of various sorts can be adequately modeled in this fashion, including of the game's structure, and the type of the other agents, \emph{e.g.} whether they are a type of agent capable of reasoning 3 epistemic levels deep or merely 2 levels deep. This is realistic for translation to the real world, and normative in that the probabilistic reasoning must abide by the axioms of probability theory. However, humans are not perfect Bayesian reasoners, so this model is unable to formally represent the mistakes humans frequently make when reasoning probabilistically without additional adjustments. A realistic model should be able to model mistakes systematically in such a way that valid inferences can be made from mistakes in belief or action.

The model presented here abandons the \SFive\ knowledge assumption in order to model how beliefs and knowledge logically relate for a new type of agent, only slightly improved over a normal human agent. This agent knows some things, believes more than she knows, and has false beliefs. She is different from normal humans in that she believes a proposition only if she has a good justification to do so, like the observation of evidence that supports the proposition, or because she believes she has made a valid inference to that proposition. The agent is realistic to the extent that a very careful human reasoner can achieve this level some of the time, when it really matters to do so, and this model is normative to the extent that an agent with more true beliefs about the environment will make better decisions after the dynamic extension of actions is layered on top. 
%We call this agent a Grounded-Coherent Agent (GCA).
%This model can subsume the models of classical game theory and bounded rationality by turning certain knobs in the metalanguage, and so in that sense the normative aspect can be dialed up at the expense of the ability to model humans who make mistakes. 

%For completeness, we describe the lowest tier of model. It is a model of normal human reasoners studied by behavioral economists and psychologists. They believe things based on systemic biases and make no effort to make a belief system consistent or grounded in evidence. Modeling such an agent from a logical standpoint is challenging for obvious reasons, and certainly these models do not pretend to be normative beyond lessons about how reasoning and beliefs can go awry, for example through cognitive biases and fallacious inferences. 

Along similar lines but in pursuit of different theoretical interests is the so-called Belief-Desire-Intention (BDI) model of action. This model seeks to explain the modules responsible for actions among humans and presumably other potential agents. The model holds that beliefs about the world, desires for how the world could be, and intentions to realize those desired states, are jointly sufficient and individually necessary conditions for actions. This model is related to the model defended here in that its agents can make mistakes due to false beliefs. 

\paragraph{2. Philosophical Foundations}
A formal epistemic theory should strive for adequate philosophical grounding in good epistemology. Hintikka took this very seriously in his 1967 book on \emph{Knowledge and Belief}~\cite{Hintikka}, which serves as a seminal work in the field of formal epistemology. Hintikka dedicates a great portion of the book to exploring how his formal system handles the intuitive judgments of philosophers regarding ordinary language statements, which was the primary method at the time. An epistemic logic divorced from a philosophical foundation is no longer an epistemic logic for reasoning about human-like knowledge. Some idealized epistemic logics can serve as logics for reasoning about machine knowledge in closed worlds, but as machines come to interact with larger and more complex parts of the world, these idealized logics diminish in adequacy, as computational limitations prevent the machine from implementing even a perfect Bayesian reasoning system. Thus, careful consideration of an epistemic logic's philosophical foundation is in order.

Epistemologists primarily seek a theory of justification that can avoid Gettier-style counterexamples~\cite{Gettier} and a theory of knowledge that can solve the problem of skepticism. A system of formal epistemology should respect these questions by coherently addressing them. We consider it required for a system of epistemic logic to be evaluated as a theory of epistemology. The epistemic logic of \SFive\ with common knowledge does not strive for this. We briefly recount some broad positions of interest from epistemology that our model should take a considered position on.


\subparagraph{The Space of Justification Theories}
Epistemology is the study of knowledge, and knowledge is widely held to require truth and justified beliefs in some way, with perhaps additional conditions being required for a jointly sufficient set of conditions. Our model defines truth through the semantic $\models$ relation between worlds and formulas, and knowledge explicitly requires belief via the axiom \emph{Knowledge implies Belief}. Justification remains for us to elaborate, although we do not model it explicitly with a justification modal operator. A theory of epistemic justification must respond to the infinite regress argument which concludes that justified beliefs are impossible. The infinite regress argument against justification runs as follows:
\begin{enumerate}
	\item A belief that $\varphi$ is justified if and only if the belief that $\varphi$ is justified by other justified beliefs.
	\item A justification chain of beliefs either: (a) terminates with unjustified base beliefs, or (b) is circular, or (c) is infinite and non-circular.
	\item If (a), then no beliefs are justified.
	\item If (b), then no beliefs are justified.
	\item If (c), then no beliefs are justified.
	\item Therefore, justification is impossible for beliefs.
\end{enumerate}
A theory of justification is shaped by how it responds to this regress argument. Denying premise (1) requires a theory to explain what, other than beliefs, justifies beliefs. Popular candidates include experiential mental states. This involves justification flowing from something that is not true or false to something true or false, and thus is not easily formalized in a logic. Denying premise (3) pushes one toward a \emph{foundationalist} theory, where the task then is to describe how a foundation of basic beliefs can be justified, and how the principle of premise (1) does not properly apply to them. Denying premise (4) pushes one toward \emph{coherentism}, where the task is to justify how a circular chain of beliefs is not viciously circular. Denying premise (5) pushes one toward \emph{infinitism}, where the task is to justify how an incomplete infinite chain can have justified constituent beliefs.

In addition to responding to the regress argument, a theory of epistemic justification must present an analysis of what constitutes justification. In addressing the regress argument, a theory takes a position about the structure of the justification relation and whether believes are of a single type or of multiple types. A theory must then take a position about the definition of the justification relation so as to avoid the problem of skepticism.


\subparagraph{Skepticism}
We take it as a basic assumption that human knowledge is possible, and therefore that the epistemic position of general skepticism is false. Therefore, in constructing a formal model of epistemic logic, that model should not lead to general skepticism when applied to humans. 

In addition to addressing the infinite regress argument, theories of justification must address an argument from logical closure. The logical closure argument runs as follows:
\begin{enumerate}
	\item $i$ knows that $\varphi$ only if $i$ knows $\tlnot$\emph{skeptical hypothesis}, where \emph{skeptical hypothesis} is some proposition that entails $\tlnot \varphi$.
	\item $i$ does not know $\tlnot$\emph{skeptical hypothesis}.
	\item Therefore, $i$ does not know $\varphi$.
\end{enumerate}

Denying (1) denies that knowledge is closed under logical entailment, and denying (2) requires care so that the theory will generalize and avoid all potential skeptical scenarios. Denying (1) presents a significant problem for formal epistemologists hoping to create a normal modal logic of knowledge. Common attempts to deny (2) include placing knowledge in a direct justification relation with the real world via causation, or defending a position that some hypotheses can be justifiably ignored from consideration. 

A theory of justification is internalist if it holds that the believer is justified in believing some proposition $\varphi$ if and only if she has awareness or access to the basis for believing $\varphi$. Externalist theories deny this, and hold that external facts, \emph{e.g.} the causal process that produced the belief, are what justify beliefs and produce knowledge. Theories of justification sometimes apply to both knowledge and justified belief, and sometimes to just one or the other.

An example internalist view is that, through reflection, one can know that she knows a propostion, and know that she believes but does not know a proposition~\cite{Prichard}. This corresponds to including both introspection axioms for the knowledge operator. A weaker internalist view that we endorse is \emph{evidentialism}, which holds that a belief is justified if and only if the believer has evidence supporting the belief. The task of an \emph{evidentialist} theory is to spell out what evidence is.

An example externalist position is that the process that produced the belief that $\varphi$ be a \emph{reliable} one, in some sense to be defined by a given \emph{reliablist} theory. This avoids the problem of skepticism by placing the justification relation between the world and the knowledge of the agent, with or without the agent's awareness of this justification being present. Thus, if $\varphi$ is true, and $i$'s belief that $\varphi$ is produced by a reliable process in the real world, then $i$ knows that $\varphi$ and therefore knows that the \emph{skeptical hypothesis} is false, because inferring that from their being inconsistent is also a reliable process. This approach clearly rejects both positive and negative introspection axioms, as introspection plays no role in the justification of knowledge.

The problem for an epistemic logician constructing a formal theory is to select an appropriate target for formalization. Most recent work avoids this problem by instead focusing on technical innovations applied to toy problems. We deny ourselves that route, and in doing so much make decisions regarding the above problems in a way that we can philosophically defend.
%The positive introspection axiom destroys almost all knowledge through the application of its contrapositive, $\tlnot \Kns{i}\Kns{i}\varphi \iimplies \tlnot \Kns{i}\varphi$. Thus, if strong internalism about knowledge is true, then knowledge is extremely rare. Knowing that one knows a proposition $\varphi$ amounts to satisfying all the conditions of knowledge with respect to the proposition that one knows $\varphi$. This means that in addition to satisfying all the conditions of knowledge with respect to $\varphi$, including the external conditions of justification, one must also be in a position to know that those external conditions are in fact satisfied. On a causal theory of justification, this amounts to knowing, actually \emph{knowing}, the exact causal process that produced your knowledge, and that this is a justifying causal process. An internalist theory of knowledge suffers from an infinite regress about the condition that known propositions be true. With the positive introspection axiom, $\Kns{i}\varphi$ only if $\Kns{i}\Kns{i}\varphi$, and $\Kns{i}\Kns{i}\varphi$ only if $\Kns{i}\Kns{i}\Kns{i}\varphi$, etc. At each layer, even for an internalist theory of knowledge, there is one externalist condition of knowledge, namely that the known proposition actually be true of the world. This amounts to knowing things in the object language about the metalanguage semantics, creating an infinitely high semantic tower that must be known in order for one atomic proposition to be known. The demands on knowledge are exceedingly high. Therefore, externalist positions about knowledge ought to, and frequently do, abandon the positive introspection requirement.

%\subparagraph{Open World Property}
%A formal model of human knowledge should do right by the world that humans know things about, to the largest extent as is reasonable. This means abiding by the open world property,
%
%
%\begin{definition}[Open World Property]~\label{owp}\newline
%	For some $p$, $p$ is an atomic proposition and $p \not \in AtProp$.
%\end{definition}
%The open world property obviously leads to an immediate contradiction with the negative introspection axiom. Formally, where $w$ is taken to be the actual world,
%\begin{enumerate}
%	\item $\exists p$ such that $w \models \tlnot \Kns{i}p$
%	\item $w \models \tlnot \Kns{i}\tlnot \Kns{i}\varphi$, by the open world property of reality.
%	\item $w \models \Kns{i}\varphi$, by the negative introspection axiom.
%\end{enumerate}




%As with Hintikka's work, the test of an epistemic logic's adequacy is its ability to correctly handle touchstone cases from the philosophical literature, or better yet, to adequately explain problems that currently lack convincing explanations. For example, the so-called Moore's sentence is a problem pervasive in epistemology and the philosophy of language, attributed to G.E. Moore~\cite{Moore} by Wittgenstein~\cite{Wittgenstein}. The standard Moore's paradox to be solved is a statement of the form,
%\begin{center}
%	\emph{$\varphi$, but I don't believe that $\varphi$.}
%\end{center}

%The alleged paradox of Moorean sentences is that they are not formal contradictions, but they nonetheless seem like they should be. Hintikka solves this problem by first asserting that his logic is meant for actual communicated statements, not merely sentences, and he distinguishes three new types of implication under study: virtual, epistemic, and doxastic. All implications are established by checking for a model where the antecedent is satisfiable while the consequent is falsifiable. If no such model is possible, then the implication is established. Virtual implication refers to checking for satisfiability of the negated implication in a model. Epistemic implication refers to checking for satisfiability of the negated implication with a knowledge operator distributed over it, and similarly for doxastic implication. Thus, Hintikka solves Moore's paradox by searching for a model that satisfies the above statement. Such a statement is falsifiable, and so virtual implication from $\varphi$ to $\Bels{i}\varphi$ fails. Hintikka turns then to doxastic implication, which involves distributing $\Bels{i}$ over the implication under inspection:
%\begin{center}
%	$\Bels{i}\varphi \tland \tlnot \Bels{i}\Bels{i}\varphi$.
%\end{center}

%This is justified by the principle that people normally believe what they assert as statements. Hintikka's doxastic logic has a transitive doxastic relation, so it takes positive introspection about belief as an axiom, and therefore the above formalization is not satisfiable in a model (and so is doxastically implied). 

\paragraph{3. Formal Properties}

A system of logic ought to be sound and complete. An epistemic logic with both belief and knowledge operators must avoid an equivalence collapse of the knowledge and belief operator, which can occur if one is not careful in choosing axioms. However, the logic must satisfy the intuition that for $v$ to be epistemically possible from $w$, $v$ and $w$ should in some sense be indistinguishable to the agent. Finally, for a logic of sufficient expressive power, namely one with agents who can reason about their own reasoning, it must avoid a special obstacle to an agent trusting its own conclusion, dubbed the L\"obian Obstacle by researchers in the foundations of artificial intelligence. Modal logics with reflective reasoners must address this obstacle. 

\subparagraph{Soundness and Completeness}
Soundness and completeness are familiar properties for students of logic. They are briefly mentioned here as a reminder.
\begin{definition}[Soundness]
	Logic $\mathcal{L}$ is \emph{sound} if and only if $\models\varphi$ implies $\vdash\varphi$,
\end{definition}
where $\models\varphi$ is semantic validity of $\varphi$ and $\vdash\varphi$ is axiomatic derivability.

\begin{definition}[Completeness]
	Logic $\mathcal{L}$ is \emph{complete} if and only if $\vdash\varphi$ implies $\models\varphi$.
\end{definition}

\subparagraph{Avoid $\mathbf{KB}$ Collapse}
Knowledge and belief are distinct. There are two distinguishing characteristics between them. The first is that belief and knowledge sit in a part-whole relationship to each other. $i$ knows that $\varphi$ only if $i$ believes that $\varphi$, with other necessary conditions that are jointly sufficient. The second is that knowledge of a proposition requires that the known proposition be true, while belief requires no such truth condition. If an epistemic logic with operators for belief and knowledge collapses them into equivalence, such that $\Bels{i}\varphi \iiff \Kns{i}\varphi$, it has gone wrong, and is not acceptable.

An offending theorem flagged in the literature as responsible for equivalence collapse is $\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$, which is our axiom \emph{Confidence in Belief}. We must show that our system avoids $\Kns{}\Bels{}$ collapse.

\subparagraph{Indistinguishability}
Many find it intuitive to speak of the epistemic relation as an equivalence or indistinguishability relation, which requires it to be symmetric, transitive, and reflexive. The epistemic relation in S5 is Euclidean and reflexive, which together yield symmetry and transitivity, and therefore an equivalence relation. Equivalence relations satisfy and indistinguishability relation because each world in the equivalence class is indistinguishable from each other relative to the relation defining the class. We must show that our axiom schema can satisfy the intuition behind epistemic indistinguishability.

%\subparagraph{L\"obian Obstacle}
%The L\"obian Obstacle is a problem facing any sufficiently powerful (formally-defined) reasoner. It refers to L\"ob's Theorem. The modal version of L\"ob's Theorem is
%\begin{center}
%\begin{eqnarray}~\label{modal_lob}
%	\Box(\Box\varphi \iimplies \varphi) \implies \Box\varphi,
%\end{eqnarray}
%\end{center}
%where the standard interpretation is that $\Box$ denotes provability in Peano Arithmetic. When~\ref{modal_lob} is included as a theorem of a normal modal logic, it can lead to undesirable results. For epistemic logics, or logics with reflective reasoners, the result is a reasoner who is guaranteed to conclude falsehoods, despite proving or knowing or believing (however one interprets the modal operator) that they do not conclude falsehoods. 
%
%The theorem grew out of G\"odel's incompleteness results about self-referential true but unprovable statements in systems at least as strong as Peano Arithmentic. L\"ob addressed the question of self-referential statements asserting their own provability. When quantified over statements, the question concerns a system's ability to prove its own consistency. L\"ob's Theorem states that a system can prove its own consistency only if it can prove every well formed formula in its language, including contradictions. For agents who can reflect on their own reasoning, this is a disaster. This is the L\"obian Obstacle that systems must strive to avoid. Research at the foundations of artificial intelligence is actively engaged in this avoidance task, for if an artificial general intelligence, possessed of a reasoning system at least as powerful as Peano Arithmetic (which it likely shall possess), tries to establish that it can trust its own reasoning, it shall cease to reason consistently.
%
%The standard modal provability logic is \boldmath{GL}, for G\"odel L\"ob. It is a normal modal logic with~\ref{modal_lob} as an axiom. The conditions that lead to the derivation of L\"ob's Theorem for other modal logics are the following:
%\begin{enumerate}
%	\item The modal logic contains the Rule of Necessitation: From $\vdash \varphi$ infer $\vdash \Box \varphi$.
%	\item The modal logic is normal: $\Box(\varphi \iimplies \psi) \iimplies (\Box \varphi \iimplies \Box \psi)$.
%	\item The modal operator's relation is transitive, \emph{i.e.,} it is a theorem that $\Box \varphi \iimplies \Box \Box \varphi$.
%	\item The modal logic contains modal fixpoints: $\vdash \psi \iiff F(\Box\psi)$, for some formula $F$ containing $\psi$ as a subformula.
%%	 OR the logic contains reflexive agents: They can define a $\psi$ for every $\varphi$ such that $\psi \equiv \Box\psi \implies \varphi$.
%\end{enumerate}
%If these four conditions are met, the modal logic will include L\"ob's Theorem. For logic's of knowledge and belief, conditions (1)-(3) are almost unavoidable for at least one of the operators. Condition (4) is likewise challenging to avoid, as common knowledge and common belief explicitly introduce modal fixpoints, but more fundamentally, there's no principled reason to say the human-like agents being modeled are incapable of expressing a sentence $\psi \stackrel{def}{=}$ "If I know that $\psi$, then $\varphi$". Humans clearly \emph{can} articulate self-referential sentences, and at the very least, they can reason on the level of Peano Arithmetic, which is sufficient for the problem to occur. Such agents will encounter the L\"obian Obstacle, and come to know contradictions. This level of error is not desired in the model. Knowledge and belief serve as a foundation for action, so the potential to know and believe anything leads to the potential for any action to be executed in a way that seems rational to the agent.
%
%OLD BELOW\\
%This system warrants defending, as John Rushby has recently challenged the decisions. His concerns can be summarized as follows:
%\begin{enumerate}
%	\item Belief is sufficient for reasoning about pilots' actions
%	\item The axioms of Knowledge and Belief are nonstandard and seem contrived
%\end{enumerate}
%We will now address each concern and defend the axioms presented above. We note that the arguments below are our best attempts at charitably representing Rushby's arguments.

%\subsubsection*{Solely Belief?}
%Rushby makes the following argument against including operators for knowledge and belief in a multi-modal system for reasoning about pilot error, and relying instead solely on an operator for belief.
%\begin{enumerate}
%	\item A model treating only a pilot's beliefs is simpler than a model treating a pilot's beliefs about her knowledge.
%	\item If model A is simpler than model B, and A accurately models the phenomenon under investigation, then model A is preferable to model B.
%	\item Rushby's model treats only pilot belief and accurately models the phenomenon under investigation.
%	\item Therefore, the Rushby's model is preferable to the DASL model.
%\end{enumerate}

%We argue that premise 3 is false. Specifically, we argue that Rushby's model does not accurately capture the relationship between the pilot's beliefs and unsafe action.

%In Rushby's alternative model, he discusses a pilot's discernment of the presence of instrument conflict, which he assumes for simplicity to be always accurate. Is this not an assumption of knowledge for simplicity? Similarly, when the pilot is aware of the autopilot status through observing an indicator on a display or through inference from the aircraft's behavior, it is not clear that this is not a case of knowing the autopilot's status. Rushby's description of the true belief seems to make it fit with any epistemologist's theory of knowledge. 

%\subsubsection*{Knowledge and Belief Axioms}
%Knowledge is weaker here than in most epistemic logics~\cite{FHMV,DEL,Hintikka}. Knowledge is almost universally formalized as an \SFive\ modal operator, including axiom schema for positive and negative introspection. Rushby suspects that because the analyses of aviation mishaps lays the blame on a failure of negative introspection in~\cite{AhrenbachGoodloe}, the decision to exclude the negative introspection axiom from the schema appears contrived. Rushby proves that to include the negative introspection axiom would cause a collapse of knowledge and belief into equivalence, due to the axiom \emph{Confidence in Belief}: $\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$, which to our knowledge was first proved by Lenzen~\cite{Lenzen}. \emph{Confidence in Belief}, additionally, is the converse of Hintikka's choice for relating the two: $\Bels{i}\Kns{i}\varphi \iimplies \Bels{i}\varphi$. Axiom \emph{Confidence in Belief} will be defended below. Rushby's concern with the knowledge axioms, or lack thereof, can be summarized as follows.
%
%\begin{enumerate}
%	\item Negative introspection is a standard axiom for epistemic logic.
%	\item \emph{Confidence in Belief} is non-standard for multi-modal epistemic-doxastic logics.
%	\item Including negative introspection and excluding \emph{Confidence in Belief} preserves an analysis based on false beliefs that is analytically sufficient.
%	\item Standard axioms are preferable to non-standard axioms when standard axioms are analytically sufficient.
%	\item Therefore, including negative introspection and excluding \emph{Confidence in Belief} is preferable to excluding and including respectively.
%\end{enumerate}

%Our representation of the argument here is based directly on Rushby's claims in CITE for premises 1 through 3, but premise 4 is inferred from context and was not explicitly mentioned. However, in order for the argument to be deductively valid, the premise must be included. We take it to be an unstated assumption behind Rushby's reasoning.

%We shall argue that premise 4 is false. Rushby's preference for the standard axioms, based on their preservation of an analysis based on false beliefs, fails to account for a feature of the present axioms which we shall endeavor to establish, namely that they more accurately describe real human knowledge and belief relations, whereas the standard axioms do not. Thus, while it is true that the analytical strength of the standard axioms would be preserved based on a false belief analysis, it does not follow that these axioms are preferable, because they do not accurately model human agency.

%First, we defend the exclusion of negative introspection for the knowledge operator. Negative introspection, recall, holds that $\tlnot\Kns{i}\varphi\iimplies\Kns{i}\tlnot\Kns{i}\varphi$: If an agent, $i$, does not know $\varphi$, then $i$ knows that she does not know it. When it is phrased this way, it can seem at worst a bit confusing, but not obviously false. However, consider one's response when it is phrased the following equivalent way: An agent does not know $\varphi$ \emph{only if} she knows that she does not know $\varphi$. This deformalized version of the axiom makes it clear that knowledge of ignorance is being asserted as a \emph{necessary condition} for ignorance, or lack of knowledge. One would be hard pressed to find an epistemologist willing to defend this view. To further elaborate on the point, consider the contrapositive: $\tlnot\Kns{i}\tlnot\Kns{i}\varphi \iimplies \Kns{i}\varphi$: If \emph{i} does not know that she does not know $\varphi$, then she knows $\varphi$. The Pyrrhonian skeptics famously denied claims to all knowledge, even to the claim that they know nothing. Thus, for all formulas $\varphi$, $\tlnot\Kns{Pyrrhonian}\tlnot\Kns{Pyrrhonian}\varphi$. According to the negative introspection axiom, then, $\Kns{Pyrrhonian}\varphi$ for arbitrary $\varphi$, certainly a result they would be disturbed by.

\section{Indistinguishibility Satisfied}\label{sec:indist}

Many find it intuitive to speak of the epistemic relation as an equivalence or indistinguishability relation, which requires it be symmetric. Symmetry, combined with the reflexivity underlying the Truth Axiom and transitivity of positive introspection, yields such an equivalence relation. It makes sense to say that world $v$ is epistemically possible from world $w$ for agent $i$ if $i$ cannot tell the two worlds apart, \emph{i.e.} they are indistinguishable. The power of this intuitive appeal presents a challenge for us. We must show that our axiom schema can satisfy the intuition behind epistemic indistinguishability without imposing symmetry on the epistemic relation.

The key to achieving this is through the composition of the doxastic relation with the epistemic relation. From a first person perspective, our model does collapse belief and knowledge together. That means that an agent cannot distinguish her mere beliefs from her genuine knowledge. Let $\Rel{k/b}^i(w)$ denote the extension of the epistemic/doxastic relation of $w$. We also define the following mathematical notion on the relations.

\begin{definition}[Doxastic Capture]
	For all $w,v,u\in W$, the doxastic capture of $w$, $dc(w)$ is defined recursively as follows:
	\begin{enumerate}
		\item $v\in dc(w)$ iff $w\Rel{b}^iv$
	\end{enumerate}
\end{definition}

We say world $w$ is \emph{path connected} to $v$ if there is some number of relational steps, $\Rel{b}^i$ and $\Rel{k}^i$ interchangeably, from $w$ to $v$. This yields the following theorem.

\begin{theorem}[Doxastic Path Capture]~\label{dpc_theorem}
For all $w,v,u\in W$, if $w\Rel{b}^iv$ and $v$ is path connected to $u$, then $v,u\in dc(w)$.
\end{theorem}
\begin{proof}
	$v\in dc(w)$ trivially from the base case of the definition of $dc(w)$. For $u$, we iteratively simplify the path between $v$ and $u$ in the following way. Since $u$ is path connected to $v$, there is some number $n$ of relational steps from $v$ to $u$. If it is by $n$ $\Rel{b}^i$ steps, then immediately $v\Rel{b}^iu$, since $\Rel{b}^i$ is transitive. Then $w\Rel{b}^iu$ as well, by transitivity through $v$.
	
	If there are $n$ steps from $v$ to $u$ interchanging $\Rel{b}^i$ and $\Rel{k}^i$, then let $x\in W$ be the first world path connected to $v$ by a $\Rel{k}^i$ step, with $m<n$ $\Rel{b}^i$ steps between $v$ and $x$. If $m=1$, then $w(\Rel{k}^i \circ \Rel{b}^i)x$, and therefore $w\Rel{b}^ix$, yielding $x\in dc(w)$. Otherwise, there are $m-1$ $\Rel{b}^i$ steps between $v$ and $x$. Examine the world at step $m-1$, call it $v'$. We have that $v\Rel{b}^iv'$ by transitivity, and therefore $w\Rel{b}^iv'$. So $v'\in dc(w)$. Since $v'\Rel{k}^ix$, $w(\Rel{k}^i \circ \Rel{b}^i)x$, and so $w\Rel{b}^ix$ and $x \in dc(w)$. This process repeats, simplifying $\Rel{b}^i$ steps by transitivity, and simplifying $(\Rel{k}^i \circ \Rel{b}^i)$ steps by the subset relation to $\Rel{b}^i$, until reaching $u$. 
\end{proof}

We also have the following.

\begin{theorem}[Doxastic Capture is Equivalence Relation]~\label{dc_equiv}
	An equivalence relation is reflexive, transitive, and Euclidean. The doxastic capture of $w$ is such a relation for both $\Rel{b}^i$ and $\Rel{k}^i$.
\end{theorem}
\begin{proof}
	It suffices to show that $\Rel{b}^i$ is reflexive and $\Rel{k}^i$ is transitive and Euclidean under $dc(w)$. Suppose $v\in dc(w)$.\\ 
	$\Rel{b}^i$-\emph{Reflexivity}. From the supposition, $w\Rel{b}^iv$. Since $\Rel{b}^i$ is serial, there is some $u$ such that $v\Rel{b}^iu$. By transitivity, $w\Rel{b}^iu$. By Euclidean, $u\Rel{b}^iv$. Since $\Rel{k}^i$ is reflexive, $v\Rel{k}^iv$. So, through $u$, $v(\Rel{k}^i \circ \Rel{b}^i)v$, and therefore $v\Rel{b}^iv$.\\
	$\Rel{k}^i$-\emph{Transitivity}. With $w\Rel{b}^iv$, let $x,y \in dc(w)$ be such that $v\Rel{k}^ix$ and $x\Rel{k}^iy$. From the definition of $dc(w)$, $w\Rel{b}^iy$. The Euclidean property yields $v\Rel{b}^iy$, and since $\Rel{b}^i\subseteq \Rel{k}^i$, it follows that $v\Rel{k}^iy$.\\
	$\Rel{k}^i$-\emph{Euclidean}. We must show $v\Rel{k}^ix$ and $v\Rel{k}^iy$ implies $x\Rel{k}^iy$. Assume $v,x,y \in dc(w)$, $v\Rel{k}^ix$, and $v\Rel{k}^iy$. By the definition of $dc(w)$, $w\Rel{b}^iv$ and $w\Rel{b}^iy$, so $v\Rel{b}^iy$ by the Euclidean property of $\Rel{b}^i$, and by $\Rel{b}^i \subseteq \Rel{k}^i$, it follows that $v\Rel{k}^iy$.
\end{proof}

Since $\Rel{k}^i$ and $\Rel{b}^i$ are part of the same bimodal equivalence relation under $dc(w)$, for all $w\in W$, the following theorems follow in a straightforward manner, establishing notions of weak and strong indistinguishability, which we call \emph{BK Indistinguishability}, highlighting the fact that behind the belief operator's doxastic relation, belief and knowledge are indistinguishable from each other, and in a mutual equivalence relation with each other.

\begin{theorem}[Weak BK Indistinguishability]~\label{weak_equiv}
	For all $w,v,w' \in W$, $w(\Rel{k}^i \circ \Rel{b}^i)v$ and $w\Rel{b}^iw'$ implies $\Rel{b}^i(w') = \Rel{k}^i(w') = \Rel{k}^i(v) = \Rel{b}^i(v)$.
\end{theorem}
\begin{proof}
	Suppose $w(\Rel{k}^i \circ \Rel{b}^i)v$ and $w\Rel{b}^iw'$ for some arbitrary $w,w',v\in W$. It suffices to show that $w',v \in dc(w)$. Since $w\Rel{b}^iw'$, $w'\in dc(w)$. Since $w(\Rel{k}^i \circ \Rel{b}^i)v$, the composed relation being a subset of $\Rel{b}^i$, it follows that $w\Rel{b}^iv$ and therefore $v \in dc(w)$.
\end{proof}

Theorem~\ref{weak_equiv} does not guarantee that the actual world $w$ is in this bimodal composed equivalence relation, because it may not be the case that $w\Rel{b}^iw$. This fails when $i$ has false beliefs, which is frequently the case with humans. However, the following is still the case: any branch departing $w$ via the $\Rel{b}^i$ relation will be a bimodal composed equivalence class of epistemic and doxastic possibility, and thus indistinguishable from each other. Any path that departs from $w$ solely by the $\Rel{k}^i$ relation will not partake in the equivalence class. The way to interpret this is as follows. For some reason, the epistemically possible worlds outside the bimodal composed equivalence class are not registering with her cognizance. It could be that she is overlooking some information. It could be that she is motivated in her skepticism for some psychological reason. It could be that she is under the cloud of some cognitive bias. Regardless, when $\varphi$ is true in the bimodal composed equivalence class but false in some epistemically possible world (\emph{e.g.} the actual world), her belief that $\varphi$ overpowers the lone epistemic relation, and she instead believes that she knows $\varphi$.

If the actual world is in its own doxastic relation, we have the following. 

\begin{theorem}[Strong BK Indistinguishability]
	For all $w,v \in W$, if $w\Rel{b}^i w$ then for all $v \in W$, $w\Rel{b}^iv$ implies $\Rel{b}^i(w) = \Rel{k}^i(w) = \Rel{k}^i(v) = \Rel{b}^i(v)$.
\end{theorem}
\begin{proof}
	Suppose for an arbitrary $w,v\in W$ that $w\Rel{b}^iw$ and $w\Rel{b}^iv$. By definition, both are in $dc(w)$, which establishes the bimodal equivalence relation.
\end{proof}

So, when $i$ has no false beliefs, her belief and knowledge collapse into an \SFive\ modal operator. When this condition holds, she makes decisions on par with those of an ideally rational agent who does not make mistakes. However, she is not guaranteed to remain in this state, as the model (world) might change in such a way that the doxastic relation comes to exclude the actual world, in which case $i$ will have false beliefs again.

Thus, in the static epistemic-doxastic logic of \DASL, the intuitively appealing property of indistinguishability is maintained from a subjective, internal standpoint, \emph{i.e.,} from $i$'s own perspective. This should be all that is needed, because the motivating intuition behind the indistinguishability requirement is that an agent should not be able to tell which of her possible worlds she is in, and that is the case here with respect to her subjective evidence.

%BELOW NEEDS WORK.
%TODO. Belief is standard~\cite{FHMV}. They are related logically by EP(1-3), which hold that knowledge entails belief, belief entails that one believes that one knows, and belief entails than one knows that one believes. Finally, actions and safe actions are logically related by SP and PR, which hold that necessary consequences of \emph{mere} action are also necessary consequences of \emph{safe} actions, and that a pilot can execute an action only if he believes that he is executing a safe action. 


%\PalPos{i}{\laa}\varphi \iimplies \Bels{i}\SPalPos{i}{\laa}\varphi$\\
\section{Avoiding The Collapse}\label{sec:collapse_avoid}

It is important that we maintain the distiction between knowledge and belief if we aim to model humans. To show that our logic maintains this distinction, we present the following counterexample.

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4cm,
		thick,base node/.style={circle,draw,minimum size=35pt}]
		

		\node[base node] (w) {\begin{tabular}{c}
			$w:  \tlnot p$ \\ $\Bels{i}p$ \\ $\tlnot\Kns{i}p $
			\end{tabular}};
		\node[base node] (v) [right of=w] {\begin{tabular}{c}
			$$\\$v: p$ \\ $$
			\end{tabular}};
		\path[]
		(w) edge[loop above] node {$\Rel{k}^i$} (w)
		(w) 
		%		edge node[below] {} (w)
		%	\draw [->] (v) edge[in=5,out=355,loop] node[right] {$R$} (v)
		edge node[above] {$\Rel{b}^i$,$\Rel{k}^i$} (v);
		
		\end{tikzpicture}
	\end{center}
	\caption{A counterexample to $\Bels{i}\varphi\iimplies\Kns{i}\varphi$.}
\end{figure}

The counterexample is based on the key difference between belief and knowledge, namely that knowledge must be true, while belief does not need to be true. Here, at $w$, the proposition $p$ is not true. However, because $i$ only considers $p$ possible, and neglects the possibility that $\tlnot p$, she believes $i$ at $w$. Since $p$ is not true at $w$, and knowledge entails truth (via the reflexivity frame condition), it is not true at $w$ that $i$ knows $p$. Therefore, at $w$, $i$ believes $p$ but she does not know it.

This suffices to show that the two modalities do not collapse. We have thus far defended the static base in terms of indistinguishibility and collapse avoidance. We turn now to soundness and completeness.

\section{Soundness and Completeness}

This section establishes the soundness and completeness of the logic.  We present mechanized formalizations of each proof in the Coq Proof Assistant. The proof of soundness shows that axioms of \DASL\ are each valid for all \DASL\ frames. The proof of completeness shows that each axiom schema is a Sahlqvist formula, and therefore forms a complete logic built by adding them to the axiom K of the minimal modal logic, by Sahlqvist's Theorem~\cite{sahlqvist}.

Both proofs make use of a special property of modal logics. Every modal logic formula is equivalent to a first- or second-order logic formula, in the sense that it is valid on the same frames as the \emph{corresponding} first- or second order formula. The frame conditions of \DASL\ are first order logic formulas, and they each correspond to an axiom schema of the modal logic. This correspondence suffices for soundness. When the modal formulas correspond to first order formulas, and the formulas have a certain special structure, the resulting logic is guaranteed to be complete with respect to the first order frame relations.

We begin this section with the soundness proof, and follow up with the completeness proof. 

\subsection{Soundness}~\label{sec:soundness}

A logic has the property of soundness \emph{if and only if} all of its derivable theorems are valid in its model theory. \DASL's model theory is the class of relational frames with two binary relations for each agent $i$, $\Rel{k}^i$ and $\Rel{b}^i$, defined over possible worlds. The $\Rel{k}^i$ relations are reflexive, and the $\Rel{b}^i$ relations are serial, euclidean, subsets of $\Rel{k}^i$, and subsets of $(\Rel{k}^i \circ \Rel{b}^i)$. Any formula satisfied by all models of this class of frames, no matter the valuation assignment of propositional variables, is a valid formula. Thus, to show that \DASL is sound is to show that all of its theorems are satisfied by all such models.

Formally, this amounts to:

\begin{theorem}[Soundness]
	Dynamic Agent Safety Logic is sound for Kripke structures with\\ (1) reflexive $\Rel{k}^i$ relations,\\ (2) serial, Euclidean $\Rel{b}^i$ relations, \\(3) which are partially ordered $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, $(\Rel{b}^i \circ \Rel{k}^i) \subseteq \Rel{b}^i$, and $\Rel{b}^i \subseteq \Rel{k}^i$.
\end{theorem}

In order to formalize this in Coq for mechanical proof checking, we must define the notions of a frame, model, proposition, and theorem. We follow the Master's thesis of Paulien De Wind \cite{dewind} for the model theory mechanization and the works of Lescanne and Puiss\'egur \cite{lescanne, puislescanne} and Malikovi\'c and \v Cubrilo \cite{delcoq1, delcoq2} in setting up the proof theory.

A frame is a record in Coq that consists of a set of possible worlds and relations on agent-world-world tuples to capture the fact that each binary relation is parameterized by each agent in the model.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Record frame : Type := {
		W : Set;
		Rk : DASL.Agents -> W -> W -> Prop;
		Rb : DASL.Agents -> W -> W -> Prop
	}.
	\end{lstlisting}	
	
\end{tcolorbox}

A model is a frame combined with a valuation function assigning worlds to atoms. We likewise create a type of agents here, imported from a library \DASL, defining them as,

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Inductive Agents: Type := Pilot | CoPilot | AutoPilot.
	\end{lstlisting}	
	
\end{tcolorbox}
 
 but any target domain's agents will suffice here.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Record model : Type := {
		F : frame;
		Val : (W F) -> Atoms -> Prop;
		Agents: DASL.Agents
	}.
	\end{lstlisting}	
	
\end{tcolorbox}

We say a proposition is an $\mathtt{Inductive}$ type of atoms, implications, negations, falsum, and the doxastic and epistemic modal operators.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Inductive prop : Type :=
		| atm : Atoms -> prop
		| imp : prop -> prop -> prop
		| negp : prop -> prop
		| falsum : prop
		| K : Agents -> prop -> prop
		| B : Agents -> prop -> prop.
	\end{lstlisting}	
	
\end{tcolorbox}

The type of $\mathtt{Atoms}$ is domain specific for the ground truth facts on which propositions in the system are built. For \DASL these are instrument readings in the cockpit, but for other domains they will be different.

A theorem type is defined in Coq so as to include all propositional tautologies, the modal axioms at the static base of \DASL, and closure through Modus Ponens and Necessitation.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Inductive theorem : prop -> Prop :=
		| Hilbert_K: forall p q : prop, theorem (p ==> q ==> p)
		| Hilbert_S: forall p q r : prop, 
			theorem ((p==>q==>r)==>(p==>q)==>(p==>r))
		| Classic_NOTNOT : forall p : prop, theorem ((NOT (NOT p)) ==> p)
		| MP : forall p q : prop, theorem (p ==> q) -> theorem p -> theorem q
		| K_Nec : forall (a : DASL.Agents) (p : prop), 
			theorem p -> theorem (K a p)
		| K_K : forall (a : DASL.Agents) (p q : prop), 
			theorem (K a p ==> K a (p ==> q) ==> K a q)
		| K_T : forall (a : DASL.Agents) (p : prop), theorem (K a p ==> p)
		| B_K : forall (a : DASL.Agents) (p q : prop),
			 theorem (B a p ==> B a (p ==> q) ==> B a q)
		 |B_Serial : forall (a : DASL.Agents) (p : prop), 
		 	theorem (B a p ==> NOT (B a (NOT p)))
		| B_5 : forall (a : DASL.Agents) (p : prop), 
			theorem (NOT (B a p) ==> B a (NOT (B a p)))
		| K_B : forall (a : DASL.Agents) (p : prop), theorem (K a p ==> B a p)
		| B_BK : forall (a : DASL.Agents) (p : prop), 
			theorem (B a p ==> B a (K a p)).
	
	\end{lstlisting}	
	
\end{tcolorbox}

We denote the $\mathtt{theorem}$ type judgment with $\mathtt{|--}$.  Our mechanical proof strategy is to follow closely what a pen-and-paper proof of soundness consists in. We will define the frame conditions of \DASL's relations, and we will prove that each is sufficient for deriving that its corresponding modal formula is valid for frames with that condition. An example will illustrate this.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Definition reflexive_Rk_frame (F : frame) : Prop := 
		forall (w : (W F)) (ags : DASL.Agents), (Rk F ags w w).
	\end{lstlisting}	
	
\end{tcolorbox}
First we define the property of epistemic reflexivity on a frame. We then prove a lemma showing it is sufficient for the Truth Axiom's being valid on reflexive frames.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Lemma K_is_refl : forall (phi : prop) (F : frame) (a : DASL.Agents),
		(reflexive_Rk_frame F) ->
		F ||= ((K a phi) ==> phi).
	Proof.
		intros.
			unfold reflexive_Rk_frame in H.
				unfold Frame_validity. 
				intros.
					unfold Model_satisfies. 
					intros. pose proof H w; clear H. pose proof H0 a; clear H0.
						unfold satisfies.
						intros. pose proof H0 w; clear H0. 
						simpl in H1. pose proof H1 H; clear H1.
		auto.
	Qed.
	\end{lstlisting}	
	
\end{tcolorbox}

We add this lemma to our $\mathtt{hints}$ so that Coq's engine will automatically try to use it on calls to $\mathtt{auto}$.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Hint Resolve K_is_refl.
	\end{lstlisting}	
	
\end{tcolorbox}

We define a \DASL\ frame as a simple conjunction over the above properties.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Definition DASL_Frame (F : frame) : Prop :=
		reflexive_Rk_frame F /\
		serial_Rb_frame F /\
		euclidean_Rb_frame F /\
		Rb_subset_Rk F /\
		Rb_subset_Rb_compose_Rk F.
	\end{lstlisting}	
	
\end{tcolorbox}

Through similar definitions and lemmas of the remaining frame conditions and axiom schemas, the soundness theorem is stated and proven as follows.
\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Theorem DASL_Soundness : forall (phi : prop) (F : frame) (a : DASL.Agents),
	DASL_Frame F ->
		|-- phi ->
		F ||= phi.
	Proof.
		intros phi F.
		unfold DASL_Frame.
		intros. destruct H; destruct H1; destruct H2; destruct H3. 
		induction H0; eauto.  
	Qed. 
	\end{lstlisting}	
	
\end{tcolorbox}

The proof proceeds by instantiating $\mathtt{phi}$, $\mathtt{F}$, $\mathtt{a}$, unfolding the definition of $\mathtt{DASL\_Frame}$ into its constituent frame conditions, and running and induction over $\mathtt{|-- phi}$. The call to $\mathtt{eauto}$ suffices due to each of the helper lemmas added to the $\mathtt{hints}$. We turn now to mechanizing completenss.

\subsection{Completeness}~\label{sec:completeness}
For completeness, our proof depends on the notion of a Sahlqvist formula, which itself depends on syntactical properties of modal formulas, which we must also define. The completeness proof is only \emph{mostly} mechanized. The overall theme of the proof is to rely on the \emph{Sahlqvist Theorem} of modal logic. This states that modal formulas with a particular structure can serve as axioms that correspond first order frame conditions in a way that guarantees soundness and completeness. We mechanized the component of the proof that establishes that the axiom schemas of \DASL\ are such \emph{Sahlqvist formulas}. 

A \emph{Sahlqvist implication} is a formula with a \emph{Sahlqvist antecedent} and a \emph{positive consequent}.

A formula is \emph{positive} if all of its propositional letters are in the scope of an even number of negation signs. A formula is \emph{negative} if one or more of its propositional letters are in the scope of an odd number of negation signs.

A \emph{Sahlqvist antecedent} is a formula built from $a)$ propositional letters prefixed by $n\geq0$ $\Box$'s and $b)$ negative formulas, $c)$ using only $\tlor$, $\tland$, and $\Diamond$ to build the antecedent from $(a)$ and $(b)$ components.

To define these notions and reason about axiom schemas rather than actual well-formed formulas of the object language, we define an inductive type in Coq that more closely resembles the formula schemas one typically uses when discussing a logic, as in $\Kns{i}\varphi \iimplies \varphi$, where $\varphi$ is a metalanguage variable standing in for any well-formed formula of the language. Because our inductive Coq type for well-formed formulas of the language is $\mathtt{prop}$, we must create an inductive type that takes $\mathtt{prop}$ as basic.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
 Inductive schema : Type :=
	| SProp : prop -> schema
	| SAnd : schema -> schema -> schema
	| SOr : schema -> schema -> schema
	| SImp : schema -> schema -> schema
	| SNeg : schema -> schema
	| SK : DASL.Agents -> schema -> schema
	| SB : DASL.Agents -> schema -> schema.
	\end{lstlisting}	
	
\end{tcolorbox}
We use the following notation symbols.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Notation ``\ p" := (SNeg p) (at level 70, right associativity).
Infix ``=s=>" := SImp (right associativity, at level 85).
Infix ``|s|" := SOr (right associativity, at level 75).
Infix ``&s&" := SAnd (right associativity, at level 75).
	\end{lstlisting}
\end{tcolorbox}
We define a $\mathtt{negative}$ formula as one whose proposition letters are all under the scope of an odd number of negation signs.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	
	Fixpoint negative_formula (phi : schema) : Prop :=
		match phi with
			| SProp p => False
			| SAnd phi1 phi2 => (negative_formula phi1) 
				/\ (negative_formula phi2)
			| SOr phi1 phi2 => (negative_formula phi1) 
				/\ (negative_formula phi2)
			| SImp phi1 phi2 => (negative_formula phi1) 
				/\ (negative_formula phi2)
			| SNeg phi' => not (negative_formula phi')
			| SK a phi' => negative_formula phi'
			| SB a phi' => negative_formula phi'
		end.
	\end{lstlisting}	
	
\end{tcolorbox}

We define a $\mathtt{positive}$ formula appropriately as one whose proposition letters are all under the scope of an even number of negation signs..

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Fixpoint positive_formula (phi : schema) : Prop :=
		match phi with
			| SProp p => True
			| SAnd phi1 phi2 => (positive_formula phi1) 
				/\ (positive_formula phi2)
			| SOr phi1 phi2 => (positive_formula phi1)
				 /\ (positive_formula phi2)
			| SImp phi1 phi2 => (positive_formula phi1)
				 /\ (positive_formula phi2)
			| SNeg phi' => not (positive_formula phi')
			| SK a phi' => positive_formula phi'
			| SB a phi' => positive_formula phi'
		end.
	\end{lstlisting}	
	
\end{tcolorbox}

To construct Sahlqvist antecedents, we define the notions of a $\mathtt{boxed}$ formula and a $\mathtt{s\_a\_component}$ (for Sahlqvist antecedent component).

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Fixpoint boxed_formula (phi : schema) : Prop :=
	match phi with
		| SProp p => True
		| SAnd phi1 phi2 => False
		| SOr phi1 phi2 => False
		| SImp phi1 phi2 => False
		| SNeg phi' => False
		| SK a phi' => boxed_formula phi'
		| SB a phi' => boxed_formula phi'
	end.
	\end{lstlisting}	
	
\end{tcolorbox}

This states that a $\mathtt{boxed\_formula}$ can be a formula variable on its own, or any number of modal boxes prefixing a formula variable, but any other structure imposed on the formula schema means it is not boxed.

A $\mathtt{s\_a\_component}$ is a formula schema built up of $\mathtt{boxed\_formula}$'s and $\mathtt{negative}$ formulas connected by conjunction, disjunction, and $\Poss{i}$, $\BPoss{i}$.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Fixpoint s_a_component (phi : schema) : Prop :=
	match phi with
		| SProp p => True
		| SAnd phi1 phi2 => (s_a_component phi1) /\ (s_a_component phi2)
		| SOr phi1 phi2 => (s_a_component phi1) /\ (s_a_component phi2)
		| SImp phi1 phi2 => not (s_a_component phi1) /\ (s_a_component phi2)
		| SNeg phi' => match phi' with
			| SProp p => True
			| SAnd p1 p2 => positive_formula p1 /\ positive_formula p2
			| SOr p1 p2 => positive_formula p1 /\ positive_formula p2
			| SImp p1 p2 => negative_formula p1 /\ positive_formula p2
			| SNeg p' => s_a_component p'
			| SK a p' => not (s_a_component p')
			| SB a p' => not (s_a_component p')
		end
		| SK a phi' => boxed_formula phi'
		| SB a phi' => boxed_formula phi'
	end.
	\end{lstlisting}	
	
\end{tcolorbox}

Next, we define what it is for a subformula to be a Sahlqvist antecedent.

\begin{tcolorbox}
\begin{lstlisting}[language=Coq]
Fixpoint sahlqvist_antecedent (phi : schema) : Prop :=
	s_a_component phi.
\end{lstlisting}
\end{tcolorbox}

We combine the above components to define what it is for a formula to be a Sahlqvist implication.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Definition sahlqvist_implication (phi psi : schema) : Prop :=
	sahlqvist_antecedent (phi) /\ positive_formula (psi).

\end{lstlisting}
\end{tcolorbox}

According to Blackburn \etal\cite{modal}, a Sahlqvist formula is built up from ``Sahlqvist implications by freely applying boxes and conjunctions, and by applying disjunctions only between formulas that do not share any proposition letters." So we must define a function that parses implications to identify when a proposition letter appears in both antecedent and consequent. We do that with the following in Coq.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Fixpoint share_prop_letter (phi psi : schema) {struct phi} : Prop :=
		match phi with
		| SProp phi' => match psi with
			| SProp psi' => phi' = psi'
			| SAnd psi1 psi2 => (prop_in_schema phi' psi1)
			 	\/ (prop_in_schema phi' psi2)
			| SOr psi1 psi2 => (prop_in_schema phi' psi1) 
				\/ (prop_in_schema phi' psi2)
			| SImp psi1 psi2 => (prop_in_schema phi' psi1) 
				\/ (prop_in_schema phi' psi2)
			| SNeg psi' => (prop_in_schema phi' psi')
			| SK a psi' => (prop_in_schema phi' psi')
			| SB a psi' => (prop_in_schema phi' psi')
			end
		| SAnd phi1 phi2 => (share_prop_letter phi1 psi) 
			\/ (share_prop_letter phi2 psi)
		| SOr phi1 phi2 => (share_prop_letter phi1 psi) 
			\/ (share_prop_letter phi2 psi)
		| SImp phi1 phi2 => (share_prop_letter phi1 psi) 
			\/ (share_prop_letter phi2 psi)
		| SNeg phi' => (share_prop_letter phi' psi)
		| SK a phi' => (share_prop_letter phi' psi)
		| SB a phi' => (share_prop_letter phi' psi)
		end.
	\end{lstlisting}
\end{tcolorbox}



To prove that \DASL\ is complete, we use the following theorem, which we have not mechanized in Coq.

\begin{theorem}[Sahlqvist's Theorem]~\label{thm:sahlqvist}
	Every Sahlqvist formula $\varphi$ defines a complete modal logic when added as an axiom to the minimal modal logic defined by the axiom K, with respect to the first order frame relation corresponding to $\varphi$,  $\mathnormal{FO}(\varphi)$.
\end{theorem}

With these components, we define a Sahlqvist formula as follows.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Fixpoint sahlqvist_formula (phi : schema) : Prop :=
	match phi with
		| SProp phi'=> True
		| SAnd phi1 phi2 => (sahlqvist_formula phi1)
			 /\ (sahlqvist_formula phi2)
		| SOr phi1 phi2 => not (share_prop_letter phi1 phi2)
			 /\ (sahlqvist_formula phi1) /\ (sahlqvist_formula phi2)
		| SImp phi1 phi2 => (sahlqvist_implication phi1 phi2)
		| SNeg phi' => ~ (positive_formula phi')
		| SK a phi' => sahlqvist_formula phi'
		| SB a phi' => sahlqvist_formula phi'
	end.
	\end{lstlisting}
\end{tcolorbox}
 
For completeness, it suffices to show that each static \DASL\ axiom schema is a Sahlqvist formula. Because in our soundess proof we mechanically proved that the \DASL\ frame conditions correspond to the axiom schemas of \DASL, and because this correspondence consists of unique pairs per the theorem, it follows that those frame conditions are the ones for which the axioms schemas are complete.

%In order to make use of Theorem \ref{thm:sahlqvist}, we characterize the Negative Belief Introspection axiom as the equivalent contrapositive $\BPoss{i}\Bels{i}\varphi \iimplies \Bels{i}\varphi$, as in below:

%\begin{table}[H]
%	\begin{center}
%		\begin{tabular}{| l r |}
%			\hline
%			$\Kns{i}(\varphi \iimplies \psi) \iimplies (\Kns{i}\varphi \iimplies \Kns{i}\psi)$ & Distribution of $\Kns{i}$ \\
%			$\Kns{i}\varphi \iimplies \varphi$ & Truth Axiom \\
%			$\Bels{i}(\varphi \iimplies \psi) \iimplies (\Bels{i}\varphi \iimplies \Bels{i}\psi)$ & Distribution of $\Bels{i}$\\
%			$\Bels{i}\varphi \iimplies \BPoss{i}\varphi$ & Belief Consistency Axiom\\
%			%			$\Bels{i}\varphi \iimplies \Bels{i}\Bels{i}\varphi$ & Positive Belief Introspection \\
%			$\BPoss{i}\Bels{i}\varphi \iimplies \Bels{i}\varphi$ & (Sahlqvist) Negative Belief Introspection\\
%			$\Kns{i}\varphi \iimplies \Bels{i}\varphi$ & Knowledge implies Belief \\
%			$\Bels{i}\varphi \iimplies \Bels{i}\Kns{i}\varphi$ & Confidence in Belief\\
%			%			$\Bels{i}\varphi \iimplies \Kns{i}\Bels{i}\varphi$ & Beliefs are Known\\
%			From $\vdash \varphi$ and $\vdash \varphi \iimplies \psi$, infer $\vdash\psi$ & Modus Ponens\\
%			From $\vdash \varphi$, infer $\vdash \Kns{i}\varphi$ & Necessitation of $\Kns{i}$\\
%			\hline
%		\end{tabular}
%		\caption{Equivalent Static Base with Sahlqvist-friendly Negative Belief Introspection.}
%	\end{center}
%\end{table}

We can represent a theory of modal logic as a list of axiom schemas, and represent \DASL\ in particular as the following list.

\begin{tcolorbox}
		\begin{lstlisting}[language=Coq]
	Definition DASL_Axioms (p q r : prop) (a : DASL.Agents) := 
	(SK a (SProp p) =s=> SK a ((SProp p) =s=> (SProp q)) =s=> SK a (SProp q))
	:: (SK a (SProp p) =s=> (SProp p))
	:: (SB a (SProp p) =s=> SB a ((SProp p) =s=> (SProp q)) =s=> SB a (SProp q))
	:: (SB a (SProp p) =s=> \ (SB a (\ (SProp p))))
	:: (\ (SB a (\ (SB a (SProp p)))) =s=> SB a (SProp p))
	:: (SK a (SProp p) =s=> SB a (SProp p))
	:: (SB a (SProp p) =s=> SB a (SK a (SProp p)))
	:: nil.
	\end{lstlisting}
\end{tcolorbox}

We define a function over lists of axiom schemas to determine whether each schema is a Sahlqvist implication.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Fixpoint Complete_via_Sahlqvist (l : list formula) : Prop :=  
	match l with
	| nil => True
	| (l' :: els) => sahlqvist_formula (l') /\ 
	Complete_via_Sahlqvist (els)
	end.
	\end{lstlisting}
\end{tcolorbox}

Then we prove that \DASL\ is complete by calling $\mathtt{Complete\_via\_Sahlqvist}$ on its representative list of axiom schemas.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Theorem DASL_Axioms_Complete : forall (p q r : prop) (a : DASL.Agents),
		Complete_via_Sahlqvist (DASL_Axioms p q r a).
	\end{lstlisting}
\end{tcolorbox}

Of course, this theorem is not in the expected form of $\models \varphi \timplies \vDash \varphi$, and in fact we have only mechanized the proof that \DASL\ is complete with respect to \emph{some} set of frame relations. To show that \DASL\ is complete with respect to the very same relations as those for which we proved soundness, we must appeal to a theorem that we have not mechanized, presented in Blackburn \etal\cite{modal}. In it, they present the theorem,

\begin{theorem}[Correspondence of Sahlqvist Formula to First Order Relation]\label{thm:correspondence}
	Let $\chi$ be a Sahqvist formula. $\chi$ corresponds to exactly one first order relation $c_\chi(x)$ that defines a class of frames, and $c_\chi(x)$ is effectively computable from $\chi$ using the Sahlqvist-van Benthem Algorithm.
\end{theorem}
\begin{proof}
	See \cite{modal} chapter 3.
\end{proof}

Since $c_\chi(x)$ defines the frame, $\chi$ is valid for that class of frames. So, by our proof of soundess where we show that the corresponding modal formulas are sound for their corresponding first order frame conditions, we can infer that these are the frame conditions for which the \DASL\ axioms are complete via the Sahlqvist theorem (\ref{thm:sahlqvist}). We leave the mechanization of these steps to future work. However, we do mechanize the preservation of completeness from $\mathtt{schema}$s to $\mathtt{prop}$s:

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Lemma schema_to_prop_completeness : forall (phi : schema),
	|s- phi ->
	|-- schema_to_prop phi.
Proof.
	intros.
	induction H; simpl; try constructor.
	simpl in IHStheorem1.
	simpl in IHStheorem2. pose proof MP p q IHStheorem1; auto.
	simpl in IHStheorem; auto.
Qed.
	\end{lstlisting}
\end{tcolorbox}

To help validate our mechanization of the $\mathtt{sahlqvist\_formula}$ function in Coq, we run it against some modal formulas whose status as Sahlqvist formulas, in the positive and negative cases, is known.

L\'ob's formula $\Box(\Box \varphi \iimplies \varphi) \iimplies \Box \varphi$, the characteristic axiom of provability logic, is not a Sahlqvist formula, and lacks a first order correspondent\cite{Boolos}.

To remain in the mechanized axiom schema logic we've produced in Coq, we use the knowledge operator as the $\Box$ operator of the formula, and prove:

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Example Lob_not_sahlqvist : forall (phi : prop) (a : DASL.Agents),
		not sahlqvist_formula (
			SK a (SK a (SProp phi) =s=> (SProp phi)) =s=> SK a (SProp phi)
		).
	Proof.
	intros. unfold not. not_sahlqvist. 
	Qed.
	\end{lstlisting}
\end{tcolorbox}

It makes use of a custom tactic we use in the Coq file.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Ltac not_sahlqvist := 
		try (unfold sahlqvist_formula; 
			  unfold sahlqvist_implication; 
			  simpl; intuition).
	\end{lstlisting}
\end{tcolorbox}

We define a similar tactic for verifying that formulas are Sahlqvist formulas.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Ltac sahlqvist_reduce := 
	simpl; try (unfold sahlqvist_implication; split);
	try (unfold positive_formula; simpl; intuition);
	try (unfold sahlqvist_antecedent; simpl; intuition; unfold normal_form).
	\end{lstlisting}
\end{tcolorbox}

We make use of this tactic in, for example,

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
	Lemma B_5_is_sahlqvist : forall (phi : prop) (a : DASL.Agents),
	sahlqvist_formula (\ (SB a (\ SB a (SProp phi))) =s=> (SB a (SProp phi))).
	Proof.
		intros; sahlqvist_reduce. 
	Qed.
	\end{lstlisting}
\end{tcolorbox}

We prove that each of the modal axioms schemas of \DASL\ are Sahlqvist formulas using the above techniques, which can be seen in the appendix. Another example Sahlqvist formula that we prove is the Church-Rosser formula, $\Diamond\Box\varphi \iimplies \Box\Diamond\varphi$, again using the knowledge operator:

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Example Church_Rosser_is_sahlqvist : forall (phi : prop) (a : DASL.Agents),
	sahlqvist_formula (
		\ (SK a (\ 
			(SK a (SProp phi)))) =s=> 
			(SK a (\ (SK a (\ (SProp phi)))))).
Proof.
	intros; sahlqvist_reduce.
Qed.
	\end{lstlisting}
\end{tcolorbox}

However, if one rearranges the $\Diamond$ and $\Box$ in Church-Rosser, this yields its converse, the McKinsey formula, which is not a Sahlqvist formula: $\Box\Diamond\varphi \iimplies \Diamond \Box \varphi$, and we likewise can prove this.

\begin{tcolorbox}
	\begin{lstlisting}[language=Coq]
Example McKinsey_not_sahlqvist : forall (phi : prop) (a : DASL.Agents),
	not sahlqvist_formula (
		SK a (\ (SK a (\ (SProp phi)))) =s=> 
		\ (SK a (\ (SK a (SProp phi))))).
Proof.
	intros; not_sahlqvist.  
Qed.
	\end{lstlisting}
\end{tcolorbox}

The sharp-eyed reader might notice that we have not defined the $\mathtt{prop}$ type that appears in the above Coq formulas. Our mechanization of \DASL\ consists in two levels. The top level is that of the axiom schema, which allows us to prove theorems about the logic using a metavariable for propositions, just as one sees logicians do in papers. The metavariable represents propositions in the object language, which bottoms out in atomic propositions about airplane instruments in this case. With this architecture, one could define alternative object languages in Coq for different domains, perhaps one for driving automobiles, one for power plant operators, and one for submarine operators. Each of these domains involves well-structured relationships between the instrument readings and the actions' safety status, but each concerns different atomic propositions. However, the top level metalanguage remains the same.

Our mechanization of $\mathtt{prop}$ is discussed in the following chapter, where we present aviation mishap case studies mechanized in the object language.
%OLD BELOW
%
%\begin{tcolorbox}
%	\begin{theorem}[Soundness]
%		Dynamic Agent Safety Logic is sound for Kripke structures with\\ (1) reflexive $\Rel{k}^i$ relations,\\ (2) serial, transitive, Euclidean $\Rel{b}^i$ relations, \\(3) which are partially ordered $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, $(\Rel{b}^i \circ \Rel{k}^i) \subseteq \Rel{b}^i$, and $\Rel{b}^i \subseteq \Rel{k}^i$.
%	\end{theorem}
%\end{tcolorbox}
%$\mathbf{Proof}.$ $(1)\  and\  (2)$ correspond to the axioms that $\Kns{i}$ is a T modality and $\Bels{i}$ is a KD45 modality in the usual way. $(3)$ corresponds to EP1, EP2, and EP3. Axioms AP through SB are reduction axioms. This leaves $(4)$, corresponding to SP, and $(5)$ which corresponds to PR. Here we will prove $(5)$. Let $M$ be a Kripke structure satisfying the five conditions above. Let $A$ be an Action structure with $\laa$ and $i$ as its actual action token and agent. 
%
%We prove $(5)$ via the contrapositive of PR: $\BPoss{i}\SPal{A,\laa}\varphi \iimplies \Pal{ A,\laa}\varphi$.
%Assume $M,w \models \BPoss{i}\SPal{A,\laa}\varphi$. By the semantics of $\BPoss{i}$, there exists a $v$, such that $w\Rel{b}^i v$ and $v \models \SPal{A,\laa}\varphi$. From the semantics, it follows that forall $M',v'$, if $(M,v)\llbracket (A,\laa) \rrbracket^S (M',v')$ then $M',v' \models \varphi$. By slightly abusing the notation, and letting $(W,w)\Rel{b}^i (W,v)$ be equivalent to $w\Rel{b}^i v$, we can create the composed relation $(\llbracket (A,\laa) \rrbracket^S \circ \Rel{b}^i)$. It then holds, by condition $(5)$, that $(M,w) (\llbracket (A,\laa) \rrbracket^S \circ \Rel{b}^i) (M',v')$ implies $(M,w)\llbracket (A,\laa) \rrbracket (M',v')$. So, for all $M',v'$, if $(M,w)\llbracket (A,\laa) \rrbracket (M',v')$, then $M',v' \models \varphi$. So, $M,w \models \Pal{A,\laa}\varphi$. $\Box$
%
%%We leave out proofs of the reduction axioms for space.
%$\mathbf{Aprop: \iimplies}$. Assume $M,w \models \Pal{A,\laa}p$. We must show that $M,w \models pre(\laa)\iimplies (post(A,p) \iimplies p)$. By the semantics of $\Pal{A,\laa}$, for all $(M',w')$, if $M,w \models pre(\laa)$ and $update(M,A,w,\laa,i)= (M',w')$, then $M',w' \models p$. By definition of $post(A,p)$, if $update(M,A,w,\laa,i)=(M',w')$ and $M',w' \models p$, then $post(A,p)=p$. So, if $M,w \models pre(\laa)$, then $post(A,p) = p$, and thus $post(A,p)\iimplies p$. 
%
%$\Leftarrow$. Assume $M,w \models pre(\laa) \iimplies (post(A,p)\iimplies p)$. By the definition of $post(A,p)$, if $post(A,p)=p$ then $update(M,A,w,\laa,i)\models p$. So, if $M,w \models pre(\laa)$, then $update(M,A,w,\laa,i)\models p$. Therefore, $M,w\models \Pal{i,(A,\laa)}p$.
%
%$\mathbf{AN: \iimplies}$. Assume $M,w \models \Pal{i,(A,\laa)}\tlnot \varphi$. It suffices to show that $M,w \models pre(\laa) \iimplies \PalPos{i}{(A,\laa)}\tlnot \varphi$. From the assumption and the semantics, for all $(W',w')$, if $(M,w)\llbracket (A,\laa) \rrbracket(M',w')$ then $M',w' \models \tlnot \varphi$. So, if $M,w \models pre(\laa)$ and $update(\\M,A,w,\laa,i)=(M',w')$, then $M',w' \models \tlnot \varphi$. Assume $M,w \models pre(\laa)$, and it follows that $update(M,A,w,\laa,i)$ is defined, so there exists a $M',w'$ such that $(M,w)\llbracket (A,\laa) \rrbracket(M',w')$ and $update(M,A,i)=(M',w')$ and $M',w' \models \tlnot \varphi$. Therefore, $M,w \models pre(\laa) \iimplies \PalPos{A,\laa}\tlnot \varphi$.
%
%$\Leftarrow$. Assume $M,w \models pre(\laa) \iimplies \tlnot \Pal{A,\laa}\varphi$. This is equivalent to $M,w \models pre(\laa) \iimplies \PalPos{A,\laa}\tlnot \varphi$.  By the semantics, if $M,w \models pre(\laa)$, then there exists a $(M',w')$ such that $(M,w)\llbracket (A,\laa)\rrbracket (M',w') \aand M',w' \models \tlnot \varphi$. The relation $\llbracket (A,\laa)\rrbracket$ is functional, so $\exists$ implies $\forall$. So, for all $(M',w')$, if $(M,w)\llbracket (A,\laa)\rrbracket (M',w')$, then $M',w' \models \tlnot \varphi$, and therefore $M,w\models \Pal{A,\laa}\tlnot \varphi$.
%
%$\mathbf{AC}$ is obvious.
%
%$\mathbf{AK}$. For this proof, assume for simplicity, without loss of generality, that $Actions = \{\laa\}$.
%
%$\iimplies$. Assume $M,w \models \Pal{A,\laa}\Kns{i}\varphi$. Unfolding the semantics, for all $(M',w')$, if $(M,w)\models pre(\laa)$ and $update(M,A,w,\laa,\\i)=(M',v')$, then $M',w'\models\Kns{i}\varphi$. $M',w'\models \Kns{i}\varphi$ iff for all $v\in W$, if $w\Rel{k}^iv$ and $M,v\models pre(\laa)$ and $update(M,A,v,\laa,i)=(M',v')$ and  $\laa\chi_{k}^i\laa$, then $M',v'\models\varphi$. That is, $M,w\models \Kns{i}\Pal{A,\laa}\varphi$. 
%
%$\Leftarrow$. Assume $M,w \models pre(\laa) \iimplies \Kns{i}\Pal{i,(A,\laa)}\varphi$. We must show $M,w \models \Pal{i,(A,\laa)}\\\Kns{i}\varphi$. Thus, we must show $M,w \models pre(\laa)$ and $update(M,A,w,\laa,i)=(M',w')$ implies $M',w' \models \Kns{i}\varphi$. So it suffices to show that if $update(M,A,w,\laa,i)=(M',w')$ and $M,w\models \Kns{i}\Pal{i,(A,\laa)}\varphi$, then $M',w'\models \Kns{i}\varphi$. Assume $update(M,A,w,\\\laa,i)=(M',w')$ and $M,w\models\Kns{i}\Pal{i,(A,\laa)}\varphi$. Then for all $v$, if $w\Rel{k}^iv$, then $M,v\models\Pal{i,(A,\laa)}\varphi$. It follows that $M,v\models pre(\laa)$ and $update(M,A,v,\laa,i)=(M',v')$ implies $M',v'\models\varphi$. Since $w\Rel{k}^iv$ and $\laa\chi_{k}^i\laa$, it holds that $w'\Rel{k}^{i'}v'$. Thus, $M',w'\models\Kns{i}\varphi$.
%
%Proofs for $\mathbf{AB}$ through $\mathbf{SB}$ follow the above proofs exactly analogously. $\Box$ 
%
%Assume $M,w \models \PalPos{A,\laa}true.$ By the semantics of $\PalPos{A,\laa},$ $M,w \models pre(\laa)$ and $update(M,w,\chi)\models true$. Let $(M',w') = update(M,w,\chi)$. Then $M',w' \models true$. From $(5)$ above, it holds that $\Rel{b}^i (w) \subseteq V^s (\laa)$. $\Rel{b}$ is serial, so there is at least one such $v \in \Rel{b}^i$. Then $M,v \models pre_s(\laa)$. From (4), $M,v \models pre(\laa)$, so $update(M,v,\chi)$ is defined, call it $(M'',v')$. Because $(M'',v')$ is defined, $M'',v' \models true$. So, $M,v \models pre_s(\laa)$ and $update(M,v,\chi)\models true$. This holds for all $v$, such that $w\Rel{b}v$. Thus, $M,w \models \Bels{i}\SPalPos{A,\laa}true$. Therefore, $M,w \models \PalPos{A,\laa}true \iimplies \Bels{i}\SPalPos{A,\laa}true$. $\square$ 
%
%Next we turn to completeness.
%
%\subsection{Completeness}
%
%Completeness proofs in contemporary modal logic research follow the following format. First, a \emph{canonical model} is defined such that it belongs to the Kripke frames for which the logic under investigation is sound. The model combines validity and deducibility so that the former entails the latter. The worlds of the canonical model are sets of formulas from the language. If a formula is a member of a such a set, then it is true at the world. We define this formally below. The objective is to show that all formulas valid for the relevant Kripke frames are likewise deducible in the logic. The key is to construct the sets in a particular way, to be discussed below.
%
%The previous section proved soundness of DASL with respect to frames with a reflexive $\Rel{k}^i$ relation, a serial, transitive, Euclidean $\Rel{b}^i$ relation, which are partially ordered $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, $(\Rel{b}^i \circ \Rel{k}^i) \subseteq \Rel{b}^i$, and $\Rel{b}^i \subseteq \Rel{k}^i$, and with action relations  $\llbracket (A,\laa)\rrbracket \subseteq \llbracket (A,\laa)\rrbracket^S$, and $(\llbracket (A,\laa)\rrbracket^S \circ \Rel{b}^i) \subseteq \llbracket (A,\laa)\rrbracket$. The canonical model we proceed to define will belong to this frame. Because it belongs to this frame, the logical closure of a set of formulas will consist of valid DASL deductions. This allows us to infer deducibility from validity. First we must define the notion of a maximal consistent set.
% 
%Informally, a maximal consistent set of formulas is one that is a subset of the well-formed formulas of the language $\mathcal{L}_{DASL}$ according to the syntax presented earlier, whose members are consistent with each other, such that the set has no consistent extension. \\
%$\mathbf{Definition}$. Maximal Consistent Set.\\
%For a set of formulas $\Gamma \subseteq \mathcal{L}_{DASL}$, $\Gamma$ is maximal consistent iff\\
%1. $\Gamma$ is consistent: $\Gamma \not \vdash \bot$.\\
%2. $\Gamma$ is maximal: there is no $\Gamma'\subseteq\mathcal{L}_{DASL}$ such that $\Gamma \subset \Gamma'$ and $\Gamma'\not\vdash\bot$.\\
%
%A canonical model is a Kripke model of $\mathcal{L}_{DASL}$ with a set of worlds $W^C$ that collectively satisfy all formulas from a maximal consistent set. For our formalism here, we treat worlds as identical to sets of formulas.
%\\
%$\mathbf{Definition}$. Canonical Model. A canonical model $M^C = \langle W^C,\ \Rel{k,i}^C,\ \Rel{b,i}^C,\ w,\ V^C\rangle$ is defined:\\
%1. $W^C = \{\Gamma | \Gamma$ is maximal consistent relative to $\mathcal{L}_{DASL} \}$\\
%2. $\Gamma \Rel{k,i}^C \Delta$ iff $\Kns{i}\varphi \in \Gamma$ implies $\varphi \in \Delta$\\
%3. $\Gamma \Rel{b,i}^C \Delta$ iff $\Bels{i}\varphi \in \Gamma$ implies $\varphi \in \Delta$\\
%4. $V^C(p) = \{\Gamma \in W^C\ |\ p \in \Gamma\}$\\
%
%
%\begin{tcolorbox}
%	\begin{theorem}[Completeness]
%		The language of Dynamic Agent Safety Logic, $\mathcal{L}_{DASL}$, is complete for Kripke structures with\\ (1) reflexive $\Rel{k}^i$ relations,\\ (2) serial, transitive, Euclidean $\Rel{b}^i$ relations, \\(3) which are partially ordered $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, $(\Rel{b}^i \circ \Rel{k}^i) \subseteq \Rel{b}^i$, and $\Rel{b}^i \subseteq \Rel{k}^i$, \\(4) $\llbracket (A,\laa)\rrbracket \subseteq \llbracket (A,\laa)\rrbracket^S$%for all $\laa,\  V^s(\laa) \subseteq V^p(\laa),$ [Questionable]
%		and\\ (5) $(\llbracket (A,\laa)\rrbracket^S \circ \Rel{b}^i) \subseteq \llbracket (A,\laa)\rrbracket$.
%	\end{theorem}
%\end{tcolorbox}
%
%$\mathbf{Proof}.$ Completeness states that if a formula $\varphi$ is valid, then it is deducible. The sketch for this proceeds proceeds by contraposition. So we must show that for every formula $\varphi$ in the language $\mathcal{L}_{DASL}$, $\not\vdash\varphi \timplies \not\models\varphi.$\\
%The proof appeals to the following lemmas, proven also in~\cite{DEL,negri}:
%\begin{lemma}[Lindenbaum]
%Every consistent set of formulas is a subset of a maximal consistent set of formulas.
%\end{lemma}
%\begin{proof}
%	
%If we begin with a consistent set of $\mathcal{L}_{DASL}$ formulas $\beta$, we construct a maximal consistent set $\Gamma$ as follows:
%\begin{enumerate}
%	\item enumerate the formulas of $\mathcal{L}_{DASL}$ $\varphi_0$, $\dots \varphi_n$, $\dots$
%	\item $\Gamma_0 \equiv \beta$
%	\item $\Gamma_{n+1} \equiv \{\varphi_n\}$ if $\Gamma_{n} \vdash \varphi_n$ 
%	\item $\Gamma_{n+1} \equiv \{\tlnot \varphi_n\}$ otherwise
%	\item $\Gamma \equiv \bigcup_{n\geq0}\Gamma_n$
%\end{enumerate}
%
%We now show that $\Gamma$ is consistent. $\Gamma$ is consistent if and only if $\forall \Gamma_n \subset \Gamma$, $\Gamma_n \not\vdash \bot$. The base set $\Gamma_0$ is consistent because it is equivalent to $\beta$, which is consistent by assumption. The induction hypothesis is if $\Gamma_{n+1}$ is consistent then so is $\Gamma_{n}$. There are two ways to construct $\Gamma_{n+1}$: via step (3), or via step (4). If via (3), then the added formula $\varphi_n$ logically follows from $\Gamma_n$, and $\mathcal{L}_{DASL}$ is sound, so $\Gamma_{n+1}$ is consistent. Otherwise, if via (4), then $\varphi_n$ does not logically follow from $\Gamma_n$. Because the formulas are enumerated and examined in order, $\varphi_n$ is not in $\Gamma_n$. Thus, $\Gamma_n \cup \{\tlnot\varphi_n\} \not\vdash \bot$. Therefore, $\Gamma$ is consistent.
%
%We show $\Gamma$ is maximal by contradiction, assuming there is a $\Gamma' \subset \mathcal{L}_{DASL}$ such that $\Gamma \subset \Gamma'$ and $\Gamma'\not\vdash\bot$. Let $\varphi_n\in\Gamma'$ and $\varphi_n\not\in\Gamma$ be an arbitrary extension of $\Gamma$. We show $\Gamma' \cup \{\varphi_n\} \vdash \bot$. When constructing $\Gamma$, the procedure examined $\varphi_n$ because it is a formula of $\mathcal{L}_{DASL}$. Since $\varphi_n\not\in\Gamma$, it must be the case that $\Gamma_n\not\vdash\varphi_n$. In step (4) we set $\Gamma_{n+1}\equiv\Gamma_n\cup\tlnot\varphi_n$. Since $\tlnot\varphi_n \in \Gamma$, we would have $\Gamma\cup\varphi_n\vdash\bot$, and so $\Gamma'\vdash\bot$, contradicting the assumption. Therefore, $\Gamma$ is maximal.  
%\end{proof}
%
%%{Lindenbaum}$: Every consistent set of formulas is a subset of a maximal consistent set of formulas.\\
%\begin{lemma}[Properties]~\label{properties}
%
%If $\Gamma$ and $\Delta$ are maximal consistent sets and $\beta$ a consistent set, then:
%\begin{enumerate}
%	\item $\Gamma$ and $\Delta$ are deductively closed.
%	\item $\varphi \in \Gamma$ iff $\tlnot \varphi \not\in \Gamma$.
%%	\item $(\varphi \tland \psi) \in \Gamma$ iff $\varphi \in \Gamma$ and $\psi \in \Gamma$.
%%	\item $\Gamma \Rel{k,i}^C\Delta$ iff $\{\Kns{i}\varphi | \Kns{i}\varphi \in \Gamma\} \subseteq \Delta$.
%%	\item $\Gamma \Rel{b,i}^C\Delta$ iff $\{\Bels{i}\varphi | \Bels{i}\varphi \in \Gamma\} \subseteq \Delta$.
%%	\item $\{\Kns{i}\varphi | \Kns{i}\varphi \in \Gamma \} \vdash \psi$ iff $\{\Kns{i}\varphi | \Kns{i}\varphi \in \Gamma\} \vdash \Kns{i}\psi$.
%    \item If $\beta \not \vdash \varphi$, then there exists a maximal consistent set $\Gamma$ such that $\beta \subset \Gamma$ but $\varphi \not \in \Gamma$
%\end{enumerate}
%\end{lemma}
%\begin{proof}
%	$(1)$ clearly follows from the construction of the maximal consistent sets as seen in the proof of Lindenbaum, specifically step (3) of the process. $(2)$ holds because each formula of $\mathcal{L}_{DASL}$ was enumerated and considered, and either it or its negation is added to the growing set at steps (3) and (4). $(3)$ follows from step (4) of the construction process of maximal consistent sets in the Lindenbaum proof.  
%\end{proof}
%\begin{lemma}[Truth]~\label{truth}
%For every $\varphi \in \mathcal{L}_{DASL}$, and every maximal consistent set $\Gamma$:
%\begin{eqnarray}
%	\varphi \in \Gamma \ \mathit{iff}\ (M^C,\Gamma)\models\varphi
%\end{eqnarray}
%\end{lemma}
%\begin{proof}
%	By induction on $\varphi$, all the non-modal formulas follow straight-forwardly from the definition of $V^C(p) = \{\Gamma \in W^C\ |\ p \in \Gamma\}$. The modal formulas require some explanation. For the left to right direction, assume we have a formula $\Kns{i}\varphi \in \Gamma$. We must show that $(M^C, \Gamma) \models \Kns{i}\varphi$. The definition of $\Gamma\Rel{k,i}^C\Delta$ is that $\Kns{i}\varphi \in \Gamma$ implies $\varphi \in \Delta$. Thus, for all $\Delta \in W^C$, if $\Gamma \Rel{k,i}^C \Delta$, then $\varphi \in \Delta$. Therefore, by the semantics of $\Kns{i}$, $(M^C, \Gamma) \models \Kns{i}\varphi$.
%	
%	We prove the right to left direction by its contrapositive, and assume $\Kns{i}\varphi\not\in\Gamma$. We show $(M^C,\Gamma)\not\models\Kns{i}\varphi$. Since $\Kns{i}\varphi\not\in\Gamma$, from property (2) of Lemma~\ref{properties} it follows that $\tlnot\Kns{i}\varphi\in\Gamma$. From the semantics of $\Kns{i}$, there is some $\Delta\in W^C$ such that $\Gamma\Rel{k,i}^C\Delta$ and $(M^C,\Delta)\models\tlnot\varphi$. Therefore, $(M^C,\Gamma)\models\tlnot\Kns{i}\varphi$, and equivalently, $(M^C,\Gamma)\not\models\Kns{i}\varphi$. 	
%	
%	
%	A similar proof shows the $\Bels{i}\varphi \in \Gamma$ case, and the dynamic modalities follow from the reduction axioms.
%	%In the right to left direction, we assume $(M^C, \Gamma) \models \Kns{i}\varphi$, and must show $\Kns{i}\varphi \in \Gamma$. From the reflexivity of $\Rel{k,i}^C$, and the semantics of $\Kns{i}$, it follows that $(M^C,\Gamma)\models \varphi$, and for all $\Delta\in W^C$, if $\Gamma\Rel{k,i}^C\Delta$, then $(M^C,\Delta)\models\varphi$. By the induction hypothesis, $\varphi \in \Gamma$. Let us assume for proof by contradiction that $\Kns{i}\varphi \not \in \Gamma$. Then $\tlnot\Kns{i}\varphi\in\Gamma$, from (2) in Lemma~\ref{properties}. By the semantics of $\Kns{i}$, there is some maximal consistent set $\Delta\in W^C$ such that $\Gamma\Rel{k,i}^C\Delta$ and $(M^C,\Delta)\models\tlnot\varphi$. Thus, $(M^C,\Gamma)\models\tlnot\Kns{i}\varphi$, contradicting the assumption. 
%\end{proof}
%
%\begin{lemma}[Canonicity]~\label{canon}
%The canonical model satisfies the frame conditions of the $\mathcal{L}_{DASL}$ semantics.\\
%\end{lemma}
%\begin{proof}
%	We must show that
%	\begin{enumerate}
%	\item $\Rel{k,i}^C$ relation is reflexive,
%	\item $\Rel{b,i}^C$ relation is serial, transitive, and Euclidean,
%	\item $\Rel{b,i}^C \subseteq \Rel{k,i}^C$,
%	\item $(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, 
%	\item $(\Rel{b}^i \circ \Rel{k}^i) \subseteq \Rel{b}^i$,
%	\item $\llbracket (A,\laa)\rrbracket^S \subseteq \llbracket (A,\laa)\rrbracket$, and 	
%	\item  $(\llbracket (A,\laa)\rrbracket^S \circ \Rel{b}^i) \subseteq \llbracket (A,\laa)\rrbracket$.
%	\end{enumerate}
%	
%	We prove these by appealing to the fact that the worlds in the canonical model $M^C$ are maximal consistent sets that each contains all of the theorems of $\mathcal{L}_{DASL}$. Therefore, each of the axiom schemas of the DASL Hilbert system is true at each world. We use this to prove that the doxastic, belief, and dynamic relations on $M^C$ satisfy the above properties, thereby placing $M^C$ in the appropriate class of Kripke frames.
%	
%	For (1), we appeal to the fact that all instances of the axiom schema $\Kns{i}\varphi \iimplies \varphi$ are elements of each world in $W^C$, the set of maximal consistent sets in $M^C$. Assume an arbitrary world $(M^C, \Gamma)\models \Kns{i}\varphi$. By the axiom schema just noted, it follows that $(M^C, \Gamma)\models \varphi$. Thus, $(M^C, \Gamma)\models\Kns{i}\varphi$ implies $(M^C, \Gamma)\models\varphi$. From the definition of the canonical model above, it follows that $\Gamma\Rel{ki,}^C\Gamma$. This holds for all $\Gamma$, and so $\Rel{k,i}^C$ is reflexive.
%	
%	Condition (2) depends on the axiom schemas of the doxastic operator. 
%	
%	The schema $\Bels{i}\varphi\iimplies \BPoss{i}\varphi$ establishes that $\Rel{b,i}^C$ is serial. We assume an arbitrary world $(M^C, \Gamma)\models\BPoss{i}\varphi$. By the schema, it follows that $(M^C,\Gamma)\models\BPoss{i}\varphi$. By the semantics of $\BPoss{i}$, there exists a world $(M^C,\Delta)\models\varphi$ such that $\Gamma\Rel{b,i}^C\Delta$. Thus, for all $\Gamma\in W^C$, $\exists \Delta \in W^C$ such that $\Gamma\Rel{b,i}^C\Delta$, which is what it means to be serial.
%	
%	The schema $\Bels{i}\varphi\iimplies\Bels{i}\Bels{i}\varphi$ establishes transitivity of $\Rel{b,i}^C$.
%	
%	The schema $\BPoss{i}\varphi\iimplies\Bels{i}\BPoss{i}\varphi$.
%	
%	Condition (3) follows from the axiom schema $\Kns{i}\varphi \iimplies \Bels{i}\varphi$.
%	
%Recall the defintion of two relations $S$ and $R$ \emph{composing}:
%	\begin{eqnarray}
%	 S \circ R \equiv \{(x,z)\in X\times Z\ |\ \exists y \in Y \colon (x,y)\in R \tland (y,z) \in S\}
%	\end{eqnarray}
%	
%	Condition (4) follows from the axiom schema $\Bels{i}\varphi\iimplies\Bels{i}\Kns{i}\varphi$.
%	
%	Condition (5) follows from the axiom schema $\Bels{i}\varphi \iimplies \Kns{i}\Bels{i}\varphi$.
%	
%	Condition (6) follows from the axiom schema $\Pal{A,\laa}\varphi\iimplies\SPal{A,\laa}\varphi$.
%	
%	Condition (7) follows from the axiom schema \\
%	$\llbracket (A,\laa) \rrbracket^S \circ \Rel{b,i}^C \equiv \{(\Gamma,\Delta')\in W^C\times W^C\ |\ \exists \Delta \in W^C \colon (\Gamma,\Delta)\in \Rel{b,i}^C \tland (\Delta,\Delta') \in \llbracket(A,\laa) \rrbracket^S\}$
%	
%	
%	Must show: $\{(\Gamma,\Delta')\}\subset \llbracket (A,\laa) \rrbracket$.
%	
%	$\PalPos{iA,\laa}\varphi\iimplies\Bels{i}\SPalPos{A,\laa}\varphi$. Assume an arbitrary world $(M^C,\Gamma)\models\PalPos{A,\laa}\varphi$. By the axiom schema, it follows that $(M^C,\Gamma)\models\Bels{i}\SPalPos{A,\laa}\varphi$. By the semantics of $\Bels{i}$, it follows that $\forall \Delta\in W^C$, if $\Gamma\Rel{b,i}^C\Delta$, then $(M^C,\Delta)\models\SPalPos{A,\laa}\varphi$. We use the reduction law $SN$: $\SPal{A,\laa}\tlnot\varphi \Leftrightarrow (pre_s(\laa) \iimplies \tlnot \SPal{A,\laa}\varphi)$ to deduce the equivalent if $\Gamma\Rel{b,i}^C\Delta$, then $(M^C,\Delta)\models pre_s(\laa)$ and $(M^C,\Delta) \llbracket (A,\laa) \rrbracket^S (M^C,\Delta')$ implies $(M^C,\Delta'\models\varphi)$, which implies $update(M^C,A,\Delta,a,i)=(M^C,\Delta')$.
%	
%	
%	The semantics of $\SPal{A,\laa}$ yield $update(M^C, A, \Delta,\laa, i)=(M'^C,\Delta')$. From the assumption that $(M^C,\Gamma)\models\PalPos{A,\laa}\varphi$ and the semantics of $\PalPos{A,\laa}$, it is true that $(M^C,\Gamma) \llbracket (A,\laa) \rrbracket (M'^C,\Gamma')$ and $(M'^C,\Gamma') \models \varphi$. 
%\end{proof}
%%With these lemmas, we assume $(M^C,\Gamma)\models\varphi$ and show that $\Gamma\vdash\varphi$. From Lemma~\ref{truth}, it follows from the assumption that $\varphi\in\Gamma$. 
%With these lemmas, we assume $\not\vdash\varphi$, and show that $\not\models\varphi$. Since $\not\vdash\varphi$, the set $\{\tlnot\varphi\}$ is consistent. From Lindenbaum, $\{\tlnot\varphi\}$ is part of a maximal consistent set, call it $\Gamma$. From the Truth Lemma, $(M^C,\Gamma)\models\tlnot\varphi$. Therefore, $\not\models\varphi$.$\Box$
%
%Because the static logic is complete and we have translation axioms that convert the dynamic formulas to equivalent static ones, we can conclude that the entirety of \DASL is complete. In the next chapter we examine case studies and a mechanization of the logic.
%We can proceed by case analysis on the frame conditions and axioms in conjunction with the rules of Modus Ponens and Necessitation. For brevity, we appeal to the well-known theorems establishing that the axioms of the static fragment of DASL are complete for system T and KD45. It remains to show that EP1, EP2, EP3, SP, and PR are complete for the frame conditions. For each frame condition, we assume that there exists a valid formula that is not deducible, and derive a contradiction. 
%
%For $(3)$, assume $\varphi$ is valid for all frames with partially-ordered relations $\Rel{b}^i \subseteq \Rel{k}^i$, but that $\varphi$ is not deducible. The relation states that for all $w,v$, if $w\Rel{k}^iv$ then $w\Rel{b}^iv$. Since $\varphi$ is valid for such frames, for all $v$, if $w\Rel{k}^iv$, $v\models\varphi$, in which case $w\models\Kns{i}\varphi$. But since the knowledge relation implies the belief relation, it follows that for all $v$, $w\Rel{b}^iv$ implies $v\models \varphi$, and therefore that $w\models\Bels{i}\varphi$. Thus, the axiom EP1 is valid for such frames. Since $\varphi$ is not deducible, and the axiom EP1 is valid for all such frames, it must be that EP1 and $\tlnot \varphi$ are consistent.

%$(\Rel{k}^i \circ \Rel{b}^i) \subseteq \Rel{b}^i$, and that $\varphi$ is not deducible. Since $\varphi$ is valid, by Necessitation of $\Bels{i}$, so is $\Bels{i}\varphi$. Thus, for all $v$, if $w \Rel{b}^i v$, $v \models \varphi$. 


%induction on the structure of $\varphi$.\\
%$p$: Suppose $\tlnot p$ is consistent. Then any $M,w$ such that $w \not\in V(p)$ serve as a model/world pair for $M,w \models \tlnot p$.
%$\varphi \tland \psi$: We suppose $\tlnot (\varphi \tland \psi)$ is consistent, which is the case when $(\tlnot \varphi \tlor \tlnot \psi)$ is consistent.

\section{Dynamic Extension}~\label{sec:dynamic_ext}

The previous section established \DASL\ as a sound and complete logic, which is a desirable formal property of the static base, since the dynamic extension is reducible to the static base in finitely many steps, it is also sound and complete.

Below are the axioms characterizing the reduction laws from the dynamic logic to a purely static logic through recursive application.\\
\begin{table}[H]
	\begin{center}
		\begin{tabular}{| l r |}
			\hline & \\
			$\Pal{A,\laa}p \iiff (post(\laa, pre(\laa)) \iimplies p)$ & Atomic Consequence\\
			$\Pal{A,\laa}\tlnot \varphi \iiff (pre(\laa) \iimplies \tlnot \Pal{A,\laa}\varphi)$ & Action Negation\\
			$\Pal{A,\laa}(\varphi \tland \psi) \iiff (\Pal{A,\laa}\varphi \tland \Pal{A,\laa}\psi)$ & Action Conjunction\\
			$\Pal{A,\laa}\Kns{i}\varphi \iiff (pre(\laa)\iimplies \bigwedge_{\laa\chi_{k}^i\beta}\Kns{i}\Pal{A,\beta}\varphi)$ & Action and Knowledge\\
			$\Pal{A,\laa}\Bels{i}\varphi \iiff (pre(\laa)\iimplies \bigwedge_{\laa\chi_{b}^i\beta}\Bels{i}\Pal{A,\beta}\varphi)$ & Action and Belief\\ 
			&\\
			%    $\Pal{A,\laa}\Pal{A',\laa'}\varphi \iiff [(A,\laa);(A',\laa')]\varphi$ & Action Composition \\
			$\SPal{A,\laa}p \iiff (post(\laa, pre_s(\laa)) \iimplies p)$ & Safe Atomic Consequence\\
			$\SPal{A,\laa}\tlnot \varphi \iiff (pre_s(\laa) \iimplies \tlnot \SPal{A,\laa}\varphi)$ & Safe Action Negation\\
			$\SPal{A,\laa}(\varphi \tland \psi) \iiff (\SPal{A,\laa}\varphi \tland \SPal{A,\laa}\psi)$ & Safe Action Conjunction\\
			$\SPal{A,\laa}\Kns{i}\varphi \iiff (pre_s(\laa)\iimplies \bigwedge_{\laa\chi_{k}^i\beta}\Kns{i}\SPal{A,\beta}\varphi)$ & Safe Action and Knowledge\\
			$\SPal{A,\laa}\Bels{i}\varphi \iiff (pre_s(\laa)\iimplies \bigwedge_{\laa\chi_{b}^i\beta}\Bels{i}\SPal{A,\beta}\varphi)$ & Safe Action and Belief\\ 
			%    $\SPal{A,\laa}\SPal{A',\laa'}\varphi \iiff [(A,\laa);(A',\laa')]\varphi$ & Safe Action Composition \\
			&\\
			\hline
		\end{tabular}
		\caption{The reduction axioms of \DASL.}
	\end{center}
\end{table}

\begin{theorem}
	Translating a dynamic formula from the dynamic extension of \DASL\ via the reduction axiom schemas terminates in finitely many steps with an equivalent static formula
\end{theorem}
\begin{proof}
	It is clear from observing each of the reduction axiom schemas that they result in formulas with smaller dynamic components, \emph{i.e.} smaller parse trees for those components. Eventually an iterative application of the reduction axiom schemas results in a purely static formula that has preserved the truth of the original formula.
\end{proof}

The truth-preservation of the reduction axiom schemas has not yet been established, and we do so here.

\begin{proof}
$\mathbf{Atomic\ Consequence: \iimplies}$. Assume $M,w \models \Pal{A,\laa}p$. We must show that \\$M,w \models (post(\laa, pre(\laa)) \iimplies p)$. By the semantics of $\Pal{A,\laa}$, for all $(M',w')$, if $M,w \models pre(\laa)$ and $update(M,A,w,\laa)= (M',w')$, then $M',w' \models p$. By definition of $post(\laa,p)$, if $update(M,A,w,\laa)=(M',w')$ and $M',w' \models p$, then $post(\laa,p)=p$. So, if $M,w \models pre(\laa)$ is defined, then $post(\laa, pre(\laa)) = p$, and thus $post(A,p)\iimplies p$. 

$\Leftarrow$. Assume $M,w \models (post(\laa, pre(\laa))\iimplies p)$. By the definition of $post(\laa,p)$, if $post(\laa,p)=p$ then $update(M,A,w,\laa)\models p$. So, if $M,w \models pre(\laa)$, then $update(M,A,w,\laa)\models p$. Therefore, $M,w\models \Pal{A,\laa}p$.

$\mathbf{Atomic\ Negation: \iimplies}$. Assume $M,w \models \Pal{A,\laa}\tlnot \varphi$. It suffices to show that $M,w \models pre(\laa) \iimplies \PalPos{A,\laa}\tlnot \varphi$. From the assumption and the semantics, for all $(W',w')$, if $(M,w)\llbracket (A,\laa)_i \rrbracket(M',w')$ then $M',w' \models \tlnot \varphi$. So, if $M,w \models pre(\laa)$ and $update(M,A,w,\laa)=(M',w')$, then $M',w' \models \tlnot \varphi$. Assume $M,w \models pre(\laa)$, and it follows that $update(M,A,w,\laa)$ is defined, so there exists a $M',w'$ such that $(M,w)\llbracket (A,\laa)_i \rrbracket(M',w')$ and $update(M,A w,\laa)=(M',w')$ and $M',w' \models \tlnot \varphi$. Therefore, $M,w \models pre(\laa) \iimplies \PalPos{A,\laa}\tlnot \varphi$.

$\Leftarrow$. Assume $M,w \models pre(\laa) \iimplies \tlnot \Pal{A,\laa}\varphi$. This is equivalent to $M,w \models pre(\laa) \iimplies \PalPos{A,\laa}\tlnot \varphi$.  By the semantics, if $M,w \models pre(\laa)$, then there exists a $(M',w')$ such that $(M,w)\llbracket (A,\laa)\rrbracket (M',w') \aand M',w' \models \tlnot \varphi$. The relation $\llbracket (A,\laa)\rrbracket$ is functional, so $\exists$ implies $\forall$. So, for all $(M',w')$, if $(M,w)\llbracket (A,\laa)\rrbracket (M',w')$, then $M',w' \models \tlnot \varphi$, and therefore $M,w\models \Pal{A,\laa}\tlnot \varphi$.

$\mathbf{Action\ Conjunction}$ is obvious.

$\mathbf{Action\ and\ Knowledge}$. For this proof, assume for simplicity, without loss of generality, that $Actions = \{\laa\}$.

$\iimplies$. Assume $M,w \models \Pal{A,\laa}\Kns{i}\varphi$. Unfolding the semantics, for all $(M',w')$, if $(M,w)\models pre(\laa)$ and $update(M,A,w,\laa)=(M',v')$, then $M',w'\models\Kns{i}\varphi$. $M',w'\models \Kns{i}\varphi$ iff for all $v\in W$, if $w\Rel{k}^iv$ and $M,v\models pre(\laa)$ and $update(M,A,v,\laa)=(M',v')$ and  $\laa\chi_{k}^i\laa$, then $M',v'\models\varphi$. That is, $M,w\models \Kns{i}\Pal{A,\laa}\varphi$. 

$\Leftarrow$. Assume $M,w \models pre(\laa) \iimplies \Kns{i}\Pal{A,\laa}\varphi$. We must show $M,w \models \Pal{A,\laa}\Kns{i}\varphi$. Thus, we must show $M,w \models pre(\laa)$ and $update(M,A,w,\laa)=(M',w')$ implies $M',w' \models \Kns{i}\varphi$. So it suffices to show that if $update(M,A,w,\laa)=(M',w')$ and $M,w\models \Kns{i}\Pal{A,\laa}\varphi$, then $M',w'\models \Kns{i}\varphi$. Assume $update(M,A,w,\laa)=(M',w')$ and $M,w\models\Kns{i}\Pal{A,\laa}\varphi$. Then for all $v$, if $w\Rel{k}^iv$, then $M,v\models\Pal{A,\laa}\varphi$. It follows that $M,v\models pre(\laa)$ and $update(M,A,v,\laa)=(M',v')$ implies $M',v'\models\varphi$. Since $w\Rel{k}^iv$ and $\laa\chi_{k}^i\laa$, it holds that $w'\Rel{k}^{i'}v'$. Thus, $M',w'\models\Kns{i}\varphi$.

Proofs for $\mathbf{Action\ and\ Belief}$ through $\mathbf{Safe\ Action\ and\ Belief}$ follow the above proofs exactly analogously.

\end{proof}

Thus, the dynamic extension inherits soundness and completeness from those of the static base. We proceed now to the philosophical justification of the dynamic extension, specifically the axiom schemas of \emph{Inevitability} and \emph{Minimum Rationality}.

\subsection{Inevitability and Minimum Rationality}\label{sec:dyn_ext}

Recall the two axiom schemas under consideration.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{| l r |}
			\hline 
&\\
$\Pal{A,\laa}\varphi \iimplies \SPal{A,\laa}\varphi$ & Inevitability\\
$\PalPos{A,\laa}\varphi \iimplies \Bels{i}\SPalPos{A,\laa}\varphi$ & Minimum Rationality\\ & \\
\hline
\end{tabular}
\caption{\DASL\ axiom schemas of dynamic non-reductive character.}
\end{center}
\end{table}

The axiom schema for \emph{Inevitability} states that if engaging in action $\laa$ from action structure $A$ guarantees that $\varphi$ is true as a result, then safely engaging in that action also guarantees that $\varphi$ will result. One way to think about this is that the postcondition of a mere action is the same function as the postcondition for a safe action. The converse of \emph{Inevitability} does not hold, however, because $\pre$ is defined on a subset of worlds on which $\pre_s$ is defined for a given action, representing the notion that it is \emph{easier} to merely engage in an action than to do so safely. The subset relation here represents number of constraints. Thus there may be worlds on which the safety precondition for an action is undefined but on which the precondition is defined. When the safety precondition is undefined it is trivially true that engaging in the action safely guarantees $\varphi$, for all $\varphi$. However, $\varphi$ may not be guaranteed given mere engagement in the action.

The axiom schema for \emph{Minimum Rationality} states that if after engaging in $\laa$ $\varphi$ results, then $i$ believes that after safely engaging in $\laa$ $\varphi$ results. It is more intuitive when the implication is read as an ``only if". This axiom schema is clearly an idealization meant to contribute normative value to the logic rather than descriptive value. It can be interpreted as an assumption that the human agents being modeled do not engage in actions that they believe to be unsafe. For commercial pilots, this assumption is reasonably secure. For other domains, this assumption should be carefully noted and considered.